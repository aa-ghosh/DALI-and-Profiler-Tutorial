{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL FOR DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, WeightedRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import cv2\n",
    "import cProfile as profile\n",
    "\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator as PyTorchIterator\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator as GenIterator\n",
    "from nvidia.dali.plugin.pytorch import LastBatchPolicy\n",
    "import math\n",
    "\n",
    "DEVICE = 'cuda:1'\n",
    "DEVICE = DEVICE if torch.cuda.is_available() else 'cpu'\n",
    "THREADS = 1\n",
    "LOGSDIR = './runs'\n",
    "# DATADIR = Path('./data')\n",
    "IMAGE_DATA = '../imagenet/ILSVRC/Data/CLS-LOC/'\n",
    "EPOCHS = 300\n",
    "BATCHSIZE = 64\n",
    "# MU = 7\n",
    "TOTAL_ITERS = None\n",
    "NUMWORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import AutoLogger\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data\n",
    "DATADIR = Path('../semisupervisedMM/data')\n",
    "IMAGE_DATA = '../imagenet/ILSVRC/Data/CLS-LOC/'\n",
    "datapath = Path(IMAGE_DATA)\n",
    "imagepath = datapath/'train'\n",
    "validpath = datapath/'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled = pd.read_csv(DATADIR/'labelled.csv')\n",
    "test = pd.read_csv(DATADIR/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    def __init__(self, path, df, weak_trans, \n",
    "            batch_size, label_list=None, total_len=0, shuffle=False):\n",
    "        self.df = df\n",
    "        # self.labelled = is_labelled\n",
    "        self.total_len = total_len\n",
    "        # self.strong_trans = strong_trans\n",
    "        self.weak_trans = weak_trans\n",
    "        self.path = Path(path)\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.label_list = label_list\n",
    "        # if self.labelled:\n",
    "        if not self.label_list:\n",
    "            self.label_list = self.df.label.unique().tolist()\n",
    "        class_w = (self.df.shape[0]/self.df.label.value_counts())\n",
    "        # print(class_w)\n",
    "\n",
    "        self.weights = self.df.label.apply(lambda x: class_w[x]).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.indices = list(range(len(self)))\n",
    "        if self.shuffle:\n",
    "            shuffle(self.indices)\n",
    "        self.total_batches = 0\n",
    "        self.i = 0\n",
    "        self.n = len(self)\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        batch_2 = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            if (self.i == self.n) and (not self.total_len):\n",
    "                self.__iter__()\n",
    "                raise StopIteration()\n",
    "            \n",
    "            \n",
    "            row = self.df.iloc[self.indices[self.i]]\n",
    "            image = row.path\n",
    "            \n",
    "            f = open(self.path/image, 'rb')\n",
    "            img = (np.frombuffer(f.read(), dtype=np.uint8))    \n",
    "            batch.append(img)\n",
    "            f.close()\n",
    "\n",
    "            batch_2.append(np.array([self.label_list.index(row.label)]))\n",
    "            self.i = (self.i+1)\n",
    "            self.total_batches += 1\n",
    "            if (self.i == self.n) and (not self.total_len):\n",
    "                self.__iter__()\n",
    "                raise StopIteration()\n",
    "            elif (self.total_len) and (self.total_batches == self.total_len):\n",
    "                self.__iter__()\n",
    "                raise StopIteration()\n",
    "            self.i = self.i%self.n\n",
    "        \n",
    "        return (batch, batch_2)\n",
    "            \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = row.path\n",
    "        \n",
    "        image = Image.open(self.path/image).convert('RGB')\n",
    "        # image = cv2.cvtColor(cv2.imread(str(self.path/image)), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "\n",
    "        # if self.labelled:\n",
    "        X = self.weak_trans(image)\n",
    "        image.close()\n",
    "        y = self.label_list.index(row.label)\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "\n",
    "weak_trans = transforms.Compose([\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomPerspective(0.05),\n",
    "    transforms.RandomResizedCrop(224, (0.8, 1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dali_weak_aug(image):\n",
    "    image = fn.rotate(image, angle=fn.random.uniform(range=(0,5)))\n",
    "    image = fn.random_resized_crop(image, size=(224,224), \n",
    "                                   random_area=(0.8,1))\n",
    "    image = fn.flip(image, horizontal=fn.random.coin_flip())\n",
    "    image = fn.color_twist(image, brightness=fn.random.uniform(range=(0.8,1.2)),\n",
    "                        contrast=fn.random.uniform(range=(0.8,1.2)),\n",
    "                        saturation=fn.random.uniform(range=(0.9,1)))\n",
    "    image = fn.crop_mirror_normalize(image, \n",
    "                                mean=[123.6750, 116.2800, 103.5300], \n",
    "                                std=[58.3950, 57.1200, 57.3750],\n",
    "                                dtype=types.FLOAT)\n",
    "    return image\n",
    "\n",
    "\n",
    "def ExternalLabelledSourcePipeline(batch_size, num_threads, device_id, external_data):\n",
    "    pipe = Pipeline(batch_size, num_threads, device_id)\n",
    "    with pipe:\n",
    "        jpegs, labels = fn.external_source(source=external_data, num_outputs=2, \n",
    "                                           dtype=[types.UINT8, types.INT64])\n",
    "        images = fn.decoders.image(jpegs, device=\"mixed\")\n",
    "        images = dali_weak_aug(images)\n",
    "        pipe.set_outputs(images, labels)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_iterator = SupervisedDataset(imagepath, df=labelled, \n",
    "                                        weak_trans=weak_trans, batch_size=BATCHSIZE, \n",
    "                                        total_len=None, shuffle=True)\n",
    "\n",
    "pytorch_dl = DataLoader(labelled_iterator, batch_size=BATCHSIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "pipe_labelled = ExternalLabelledSourcePipeline(batch_size=BATCHSIZE, num_threads=THREADS, device_id = int(DEVICE.split(':')[-1]),\n",
    "                              external_data = labelled_iterator)\n",
    "\n",
    "labelled_loader = GenIterator(pipe_labelled, output_map=['x', 'y'], \n",
    "                      last_batch_padded=True, last_batch_policy=LastBatchPolicy.PARTIAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         80034 function calls (79762 primitive calls) in 0.648 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       97    0.200    0.002    0.200    0.002 {method 'transform2' of 'ImagingCore' objects}\n",
      "      135    0.190    0.001    0.190    0.001 {method 'decode' of 'ImagingDecoder' objects}\n",
      "       64    0.067    0.001    0.067    0.001 {method 'resize' of 'ImagingCore' objects}\n",
      "      192    0.051    0.000    0.051    0.000 {built-in method PIL._imaging.blend}\n",
      "      225    0.009    0.000    0.009    0.000 {built-in method PIL._imaging.fill}\n",
      "      257    0.008    0.000    0.008    0.000 {method 'convert' of 'ImagingCore' objects}\n",
      "        2    0.006    0.003    0.006    0.003 {built-in method torch.stack}\n",
      "       64    0.006    0.000    0.006    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
      "       64    0.005    0.000    0.005    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
      "       64    0.004    0.000    0.008    0.000 {built-in method numpy.array}\n",
      "       64    0.004    0.000    0.004    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "      127    0.003    0.000    0.003    0.000 {method 'copy' of 'ImagingCore' objects}\n",
      "        1    0.003    0.003    0.648    0.648 <string>:1(<module>)\n",
      "       64    0.003    0.000    0.007    0.000 transforms.py:927(get_params)\n",
      "       64    0.002    0.000    0.002    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
      "       64    0.002    0.000    0.002    0.000 {method 'crop' of 'ImagingCore' objects}\n",
      "       64    0.002    0.000    0.072    0.001 transforms.py:1267(forward)\n",
      "       33    0.002    0.000    0.002    0.000 {built-in method torch._C._linalg.linalg_lstsq}\n",
      "      425    0.002    0.000    0.002    0.000 {built-in method torch.tensor}\n",
      "     1064    0.002    0.000    0.002    0.000 {built-in method torch.empty}\n",
      "     2647    0.002    0.000    0.002    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "       64    0.002    0.000    0.002    0.000 {method 'histogram' of 'ImagingCore' objects}\n",
      "       33    0.002    0.000    0.005    0.000 functional.py:687(_get_perspective_coeffs)\n",
      "       64    0.002    0.000    0.002    0.000 ImageStat.py:77(_getsum)\n",
      "       64    0.002    0.000    0.002    0.000 {method 'div_' of 'torch._C._TensorBase' objects}\n",
      "     1062    0.002    0.000    0.002    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
      "       64    0.002    0.000    0.002    0.000 {method 'sub_' of 'torch._C._TensorBase' objects}\n",
      "       64    0.001    0.000    0.001    0.000 {built-in method PIL._imaging.new}\n",
      "      963    0.001    0.000    0.002    0.000 Image.py:543(_new)\n",
      "     1027    0.001    0.000    0.002    0.000 utils.py:538(_log_api_usage_once)\n",
      "      127    0.001    0.000    0.195    0.002 ImageFile.py:155(load)\n",
      "      192    0.001    0.000    0.001    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
      "       64    0.001    0.000    0.199    0.003 transforms.py:793(forward)\n",
      "8964/8959    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "      448    0.001    0.000    0.001    0.000 {built-in method posix.lstat}\n",
      "      448    0.001    0.000    0.390    0.001 module.py:1494(_call_impl)\n",
      "       34    0.001    0.000    0.001    0.000 {method 'transpose' of 'ImagingCore' objects}\n",
      "       84    0.001    0.000    0.001    0.000 {method 'join' of 'bytes' objects}\n",
      "       64    0.001    0.000    0.004    0.000 JpegImagePlugin.py:351(_open)\n",
      "       64    0.001    0.000    0.008    0.000 _functional_tensor.py:905(normalize)\n",
      "      348    0.001    0.000    0.001    0.000 {built-in method torch.randint}\n",
      "      320    0.001    0.000    0.207    0.001 Image.py:889(convert)\n",
      "       64    0.001    0.000    0.026    0.000 functional.py:125(to_tensor)\n",
      "     1507    0.001    0.000    0.001    0.000 Image.py:835(load)\n",
      "     1252    0.001    0.000    0.001    0.000 Image.py:512(__init__)\n",
      "       64    0.001    0.000    0.002    0.000 transforms.py:711(forward)\n",
      "       64    0.001    0.000    0.637    0.010 3599899832.py:65(__getitem__)\n",
      "        2    0.001    0.000    0.001    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "       64    0.001    0.000    0.003    0.000 posixpath.py:401(_joinrealpath)\n",
      "      512    0.001    0.000    0.001    0.000 posixpath.py:71(join)\n",
      "       64    0.001    0.000    0.416    0.006 transforms.py:93(__call__)\n",
      "     1027    0.001    0.000    0.001    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "       64    0.001    0.000    0.001    0.000 {built-in method io.open}\n",
      "      128    0.001    0.000    0.001    0.000 {built-in method torch.rand}\n",
      "      128    0.001    0.000    0.001    0.000 pathlib.py:56(parse_parts)\n",
      "      128    0.001    0.000    0.071    0.001 functional.py:391(resize)\n",
      "      225    0.001    0.000    0.001    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "      403    0.001    0.000    0.001    0.000 {built-in method torch.exp}\n",
      "      128    0.001    0.000    0.001    0.000 {built-in method torch.as_tensor}\n",
      "       98    0.001    0.000    0.001    0.000 JpegImagePlugin.py:61(APP)\n",
      "     1027    0.001    0.000    0.001    0.000 _trace.py:1101(is_tracing)\n",
      "      320    0.001    0.000    0.003    0.000 functional.py:64(get_dimensions)\n",
      "     1077    0.001    0.000    0.001    0.000 {built-in method builtins.round}\n",
      "      128    0.001    0.000    0.068    0.001 Image.py:2089(resize)\n",
      "       64    0.000    0.000    0.021    0.000 Image.py:2227(rotate)\n",
      "     1220    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "      320    0.000    0.000    0.001    0.000 _functional_pil.py:22(get_dimensions)\n",
      "      127    0.000    0.000    0.001    0.000 JpegImagePlugin.py:243(DQT)\n",
      "       65    0.000    0.000    0.000    0.000 {built-in method torch.randperm}\n",
      "       64    0.000    0.000    0.010    0.000 ImageEnhance.py:65(__init__)\n",
      "       64    0.000    0.000    0.006    0.000 Image.py:3242(_open_core)\n",
      "      127    0.000    0.000    0.000    0.000 JpegImagePlugin.py:263(<listcomp>)\n",
      "      225    0.000    0.000    0.010    0.000 Image.py:2896(new)\n",
      "      192    0.000    0.000    0.003    0.000 generic.py:5888(__getattr__)\n",
      "      768    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "      512    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method torch.log}\n",
      "       97    0.000    0.000    0.001    0.000 _functional_pil.py:253(_parse_fill)\n",
      "       97    0.000    0.000    0.200    0.002 Image.py:2719(__transformer)\n",
      "     1795    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method _functools.reduce}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'unbind' of 'torch._C._TensorBase' objects}\n",
      "       97    0.000    0.000    0.210    0.002 Image.py:2629(transform)\n",
      "3266/3196    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       64    0.000    0.000    0.001    0.000 posixpath.py:338(normpath)\n",
      "       64    0.000    0.000    0.003    0.000 Image.py:729(tobytes)\n",
      "       64    0.000    0.000    0.000    0.000 JpegImagePlugin.py:193(SOF)\n",
      "      128    0.000    0.000    0.001    0.000 series.py:966(__getitem__)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
      "     1060    0.000    0.000    0.000    0.000 _functional_pil.py:14(_is_pil_image)\n",
      "       64    0.000    0.000    0.013    0.000 Image.py:3174(open)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'any' of 'torch._C._TensorBase' objects}\n",
      "      673    0.000    0.000    0.001    0.000 Image.py:1312(getbands)\n",
      "       64    0.000    0.000    0.001    0.000 transforms.py:1235(get_params)\n",
      "      737    0.000    0.000    0.000    0.000 ImageMode.py:36(getmode)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
      "     1671    0.000    0.000    0.001    0.000 _binary.py:80(i16be)\n",
      "       33    0.000    0.000    0.001    0.000 transforms.py:815(get_params)\n",
      "       64    0.000    0.000    0.003    0.000 frame.py:3703(_ixs)\n",
      "      612    0.000    0.000    0.000    0.000 ImageFile.py:555(_safe_read)\n",
      "     1862    0.000    0.000    0.000    0.000 {built-in method _struct.unpack_from}\n",
      "       34    0.000    0.000    0.000    0.000 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
      "       64    0.000    0.000    0.001    0.000 Image.py:572(close)\n",
      "      645    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       64    0.000    0.000    0.001    0.000 managers.py:1078(fast_xs)\n",
      "      128    0.000    0.000    0.000    0.000 base.py:5254(__contains__)\n",
      "      128    0.000    0.000    0.001    0.000 pathlib.py:569(_parse_args)\n",
      "       64    0.000    0.000    0.008    0.000 functional.py:340(normalize)\n",
      "       64    0.000    0.000    0.005    0.000 ImageFile.py:88(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:5844(__finalize__)\n",
      "       64    0.000    0.000    0.022    0.000 functional.py:1074(rotate)\n",
      "     1027    0.000    0.000    0.000    0.000 {built-in method torch._C._is_tracing}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method torch.from_numpy}\n",
      "     1443    0.000    0.000    0.000    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
      "      192    0.000    0.000    0.052    0.000 Image.py:3305(blend)\n",
      "        1    0.000    0.000    0.637    0.637 fetch.py:51(<listcomp>)\n",
      "       64    0.000    0.000    0.004    0.000 indexing.py:1592(_getitem_axis)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
      "   192/64    0.000    0.000    0.003    0.000 ImageStat.py:43(__getattr__)\n",
      "      128    0.000    0.000    0.068    0.001 _functional_pil.py:238(resize)\n",
      "     2055    0.000    0.000    0.000    0.000 _jit_internal.py:1102(is_scripting)\n",
      "      318    0.000    0.000    0.001    0.000 JpegImagePlugin.py:56(Skip)\n",
      "     1633    0.000    0.000    0.000    0.000 Image.py:539(size)\n",
      "      192    0.000    0.000    0.000    0.000 pathlib.py:621(__str__)\n",
      "       33    0.000    0.000    0.196    0.006 functional.py:715(perspective)\n",
      "       64    0.000    0.000    0.001    0.000 transforms.py:1352(get_params)\n",
      "      768    0.000    0.000    0.000    0.000 {built-in method sys.intern}\n",
      "     2381    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "       64    0.000    0.000    0.072    0.001 functional.py:610(resized_crop)\n",
      "       64    0.000    0.000    0.024    0.000 transforms.py:1362(forward)\n",
      "      128    0.000    0.000    0.001    0.000 generic.py:5904(__setattr__)\n",
      "       64    0.000    0.000    0.001    0.000 ImageStat.py:69(_getcount)\n",
      "       64    0.000    0.000    0.001    0.000 blocks.py:2172(new_block)\n",
      "       64    0.000    0.000    0.002    0.000 Image.py:1236(_crop)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:259(__init__)\n",
      "      128    0.000    0.000    0.000    0.000 base.py:5934(_get_values_for_loc)\n",
      "       64    0.000    0.000    0.080    0.001 transforms.py:971(forward)\n",
      "      225    0.000    0.000    0.000    0.000 Image.py:2875(_check_size)\n",
      "     1060    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       64    0.000    0.000    0.002    0.000 ImageStat.py:30(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "      128    0.000    0.000    0.000    0.000 managers.py:2069(internal_values)\n",
      "       64    0.000    0.000    0.000    0.000 Image.py:417(_getencoder)\n",
      "      384    0.000    0.000    0.000    0.000 Image.py:525(__getattr__)\n",
      "       64    0.000    0.000    0.006    0.000 pathlib.py:1064(resolve)\n",
      "      161    0.000    0.000    0.000    0.000 _functional_pil.py:41(get_image_num_channels)\n",
      "       64    0.000    0.000    0.003    0.000 ImageStat.py:99(_getmean)\n",
      "      127    0.000    0.000    0.004    0.000 Image.py:1197(copy)\n",
      "       64    0.000    0.000    0.005    0.000 JpegImagePlugin.py:821(jpeg_factory)\n",
      "       64    0.000    0.000    0.022    0.000 _functional_pil.py:298(rotate)\n",
      "       64    0.000    0.000    0.005    0.000 ImageEnhance.py:48(__init__)\n",
      "      128    0.000    0.000    0.001    0.000 series.py:1072(_get_value)\n",
      "      128    0.000    0.000    0.000    0.000 common.py:162(is_object_dtype)\n",
      "       64    0.000    0.000    0.004    0.000 indexing.py:1059(__getitem__)\n",
      "      128    0.000    0.000    0.000    0.000 base.py:3754(get_loc)\n",
      "       33    0.000    0.000    0.000    0.000 {built-in method torch.zeros}\n",
      "       64    0.000    0.000    0.003    0.000 Image.py:687(__array_interface__)\n",
      "       64    0.000    0.000    0.028    0.000 functional.py:898(adjust_contrast)\n",
      "       64    0.000    0.000    0.019    0.000 functional.py:876(adjust_brightness)\n",
      "       64    0.000    0.000    0.022    0.000 functional.py:920(adjust_saturation)\n",
      "       64    0.000    0.000    0.001    0.000 _tensor.py:920(__iter__)\n",
      "       64    0.000    0.000    0.001    0.000 pathlib.py:615(_make_child)\n",
      "      192    0.000    0.000    0.000    0.000 indexing.py:2656(check_deprecated_indexers)\n",
      "       64    0.000    0.000    0.000    0.000 Image.py:393(_getdecoder)\n",
      "      640    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
      "       64    0.000    0.000    0.001    0.000 posixpath.py:377(abspath)\n",
      "       64    0.000    0.000    0.003    0.000 Image.py:1210(crop)\n",
      "      128    0.000    0.000    0.001    0.000 base.py:5363(_can_hold_identifiers_and_holds_name)\n",
      "      960    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "       64    0.000    0.000    0.000    0.000 Image.py:248(_conv_type_shape)\n",
      "      128    0.000    0.000    0.001    0.000 base.py:2581(is_object)\n",
      "      192    0.000    0.000    0.052    0.000 ImageEnhance.py:25(enhance)\n",
      "       64    0.000    0.000    0.004    0.000 posixpath.py:392(realpath)\n",
      "       64    0.000    0.000    0.000    0.000 series.py:611(name)\n",
      "       64    0.000    0.000    0.001    0.000 series.py:342(__init__)\n",
      "       64    0.000    0.000    0.001    0.000 ImageEnhance.py:82(__init__)\n",
      "       64    0.000    0.000    0.028    0.000 _functional_pil.py:77(adjust_contrast)\n",
      "       64    0.000    0.000    0.003    0.000 functional.py:544(crop)\n",
      "      192    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
      "       64    0.000    0.000    0.000    0.000 ImageFile.py:229(<listcomp>)\n",
      "      128    0.000    0.000    0.000    0.000 pathlib.py:239(splitroot)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
      "      128    0.000    0.000    0.000    0.000 common.py:1591(_is_dtype_type)\n",
      "       64    0.000    0.000    0.000    0.000 blocks.py:2091(maybe_coerce_values)\n",
      "       64    0.000    0.000    0.000    0.000 indexing.py:1539(_validate_integer)\n",
      "      128    0.000    0.000    0.000    0.000 pathlib.py:608(_format_parsed_parts)\n",
      "      192    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "      128    0.000    0.000    0.000    0.000 posixpath.py:60(isabs)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method PIL._imaging.jpeg_decoder}\n",
      "       33    0.000    0.000    0.190    0.006 _functional_pil.py:315(perspective)\n",
      "       64    0.000    0.000    0.000    0.000 blocks.py:2120(get_block_type)\n",
      "       64    0.000    0.000    0.022    0.000 _functional_pil.py:87(adjust_saturation)\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:564(_get_axis)\n",
      "       64    0.000    0.000    0.018    0.000 _functional_pil.py:67(adjust_brightness)\n",
      "      128    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "       64    0.000    0.000    0.026    0.000 transforms.py:129(__call__)\n",
      "      128    0.000    0.000    0.000    0.000 pathlib.py:631(__fspath__)\n",
      "       64    0.000    0.000    0.000    0.000 series.py:661(name)\n",
      "       64    0.000    0.000    0.002    0.000 ImageFile.py:292(load_prepare)\n",
      "      512    0.000    0.000    0.000    0.000 {method 'partition' of 'str' objects}\n",
      "      388    0.000    0.000    0.000    0.000 _functional_pil.py:275(<genexpr>)\n",
      "       65    0.000    0.000    0.001    0.000 sampler.py:117(__iter__)\n",
      "       64    0.000    0.000    0.000    0.000 managers.py:1891(__init__)\n",
      "      135    0.000    0.000    0.001    0.000 JpegImagePlugin.py:404(load_read)\n",
      "       64    0.000    0.000    0.000    0.000 blocks.py:2186(check_ndim)\n",
      "      806    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "       64    0.000    0.000    0.003    0.000 _functional_pil.py:223(crop)\n",
      "       64    0.000    0.000    0.000    0.000 blocks.py:827(iget)\n",
      "      225    0.000    0.000    0.000    0.000 enum.py:783(__hash__)\n",
      "       64    0.000    0.000    0.000    0.000 common.py:96(is_bool_indexer)\n",
      "      128    0.000    0.000    0.000    0.000 Image.py:3153(_decompression_bomb_check)\n",
      "       64    0.000    0.000    0.002    0.000 transforms.py:353(forward)\n",
      "      512    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "      128    0.000    0.000    0.000    0.000 functional.py:366(_compute_resized_output_size)\n",
      "      192    0.000    0.000    0.000    0.000 generic.py:45(_instancecheck)\n",
      "       64    0.000    0.000    0.008    0.000 transforms.py:269(forward)\n",
      "        1    0.000    0.000    0.644    0.644 dataloader.py:675(_next_data)\n",
      "       64    0.000    0.000    0.002    0.000 Image.py:1597(histogram)\n",
      "      384    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      128    0.000    0.000    0.000    0.000 managers.py:275(arrays)\n",
      "       34    0.000    0.000    0.001    0.000 functional.py:667(hflip)\n",
      "      192    0.000    0.000    0.000    0.000 generic.py:40(_check)\n",
      "       64    0.000    0.000    0.000    0.000 range.py:956(__getitem__)\n",
      "      417    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "       64    0.000    0.000    0.000    0.000 JpegImagePlugin.py:512(_getmp)\n",
      "      192    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "      128    0.000    0.000    0.000    0.000 series.py:708(_values)\n",
      "       64    0.000    0.000    0.001    0.000 pathlib.py:589(_from_parts)\n",
      "       64    0.000    0.000    0.000    0.000 pathlib.py:600(_from_parsed_parts)\n",
      "       64    0.000    0.000    0.000    0.000 Image.py:2315(transform)\n",
      "      128    0.000    0.000    0.000    0.000 functional.py:1596(_check_antialias)\n",
      "       64    0.000    0.000    0.000    0.000 flags.py:49(__init__)\n",
      "      192    0.000    0.000    0.000    0.000 common.py:362(apply_if_callable)\n",
      "       64    0.000    0.000    0.000    0.000 flags.py:85(allows_duplicate_labels)\n",
      "       84    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "      128    0.000    0.000    0.000    0.000 base.py:163(array)\n",
      "       64    0.000    0.000    0.000    0.000 construction.py:461(ensure_wrapped_if_datetimelike)\n",
      "      128    0.000    0.000    0.000    0.000 generic.py:640(_info_axis)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method PIL._imaging.raw_encoder}\n",
      "      128    0.000    0.000    0.000    0.000 common.py:146(classes)\n",
      "        1    0.000    0.000    0.001    0.001 dataloader.py:567(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 BmpImagePlugin.py:55(_dib_accept)\n",
      "       64    0.000    0.000    0.000    0.000 common.py:1725(validate_all_hashable)\n",
      "      384    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "      448    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
      "      128    0.000    0.000    0.000    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'setimage' of 'ImagingDecoder' objects}\n",
      "       34    0.000    0.000    0.001    0.000 Image.py:2798(transpose)\n",
      "      128    0.000    0.000    0.000    0.000 common.py:1744(<genexpr>)\n",
      "       64    0.000    0.000    0.001    0.000 pathlib.py:853(__truediv__)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
      "       64    0.000    0.000    0.000    0.000 __init__.py:1455(debug)\n",
      "       65    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "       64    0.000    0.000    0.000    0.000 _functional_tensor.py:9(_is_tensor_a_torch_image)\n",
      "       64    0.000    0.000    0.000    0.000 functional.py:115(_is_numpy)\n",
      "      128    0.000    0.000    0.000    0.000 managers.py:287(<listcomp>)\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method math.cos}\n",
      "      128    0.000    0.000    0.000    0.000 Image.py:535(height)\n",
      "       64    0.000    0.000    0.000    0.000 indexing.py:139(iloc)\n",
      "      128    0.000    0.000    0.000    0.000 common.py:148(<lambda>)\n",
      "       64    0.000    0.000    0.000    0.000 pathlib.py:1092(stat)\n",
      "       34    0.000    0.000    0.001    0.000 _functional_pil.py:51(hflip)\n",
      "       64    0.000    0.000    0.000    0.000 pathlib.py:94(join_parsed_parts)\n",
      "      128    0.000    0.000    0.000    0.000 JpegImagePlugin.py:337(_accept)\n",
      "      320    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 _functional_tensor.py:13(_assert_image_tensor)\n",
      "      128    0.000    0.000    0.000    0.000 Image.py:531(width)\n",
      "       64    0.000    0.000    0.000    0.000 inference.py:325(is_hashable)\n",
      "       64    0.000    0.000    0.000    0.000 BmpImagePlugin.py:51(_accept)\n",
      "       64    0.000    0.000    0.000    0.000 _binary.py:60(i32le)\n",
      "       64    0.000    0.000    0.000    0.000 __init__.py:1724(isEnabledFor)\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:550(_get_axis_number)\n",
      "       64    0.000    0.000    0.000    0.000 TiffImagePlugin.py:272(_accept)\n",
      "      192    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "      192    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "       66    0.000    0.000    0.000    0.000 range.py:946(__len__)\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:4114(_set_is_copy)\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x743500}\n",
      "       64    0.000    0.000    0.000    0.000 _util.py:5(is_path)\n",
      "      128    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
      "       97    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "       64    0.000    0.000    0.000    0.000 managers.py:2433(_using_copy_on_write)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method torch.get_default_dtype}\n",
      "       64    0.000    0.000    0.000    0.000 JpegImagePlugin.py:487(_getmp)\n",
      "       64    0.000    0.000    0.000    0.000 _util.py:15(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 GifImagePlugin.py:54(_accept)\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:332(attrs)\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method math.sin}\n",
      "       64    0.000    0.000    0.000    0.000 inference.py:188(is_array_like)\n",
      "       64    0.000    0.000    0.000    0.000 Image.py:321(preinit)\n",
      "       64    0.000    0.000    0.000    0.000 common.py:1420(is_1d_only_ea_dtype)\n",
      "      192    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "      127    0.000    0.000    0.000    0.000 _binary.py:84(i32be)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method math.radians}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
      "      128    0.000    0.000    0.000    0.000 generic.py:353(flags)\n",
      "       64    0.000    0.000    0.000    0.000 flags.py:53(allows_duplicate_labels)\n",
      "       64    0.000    0.000    0.000    0.000 ImageFile.py:232(<lambda>)\n",
      "       64    0.000    0.000    0.000    0.000 utils.py:66(is_list_like_indexer)\n",
      "      128    0.000    0.000    0.000    0.000 base.py:6569(_maybe_cast_indexer)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler.}\n",
      "        1    0.000    0.000    0.648    0.648 {built-in method builtins.exec}\n",
      "    68/67    0.000    0.000    0.001    0.000 {built-in method builtins.iter}\n",
      "      3/1    0.000    0.000    0.006    0.006 collate.py:87(collate)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'cleanup' of 'ImagingDecoder' objects}\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:495(__exit__)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "      128    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 managers.py:2009(_block)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:98(_get_distributed_settings)\n",
      "       64    0.000    0.000    0.000    0.000 ImageFile.py:75(_tilesort)\n",
      "        1    0.000    0.000    0.645    0.645 dataloader.py:628(__next__)\n",
      "       64    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "       64    0.000    0.000    0.000    0.000 collate.py:137(<genexpr>)\n",
      "     67/1    0.000    0.000    0.645    0.645 {built-in method builtins.next}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "       64    0.000    0.000    0.000    0.000 ImageFile.py:300(load_end)\n",
      "        5    0.000    0.000    0.000    0.000 JpegImagePlugin.py:182(COM)\n",
      "       64    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "        1    0.000    0.000    0.001    0.001 sampler.py:247(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:683(is_initialized)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        1    0.000    0.000    0.001    0.001 dataloader.py:661(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:286(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:491(__enter__)\n",
      "        2    0.000    0.000    0.006    0.003 collate.py:153(collate_tensor_fn)\n",
      "        2    0.000    0.000    0.001    0.000 sampler.py:241(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:1498(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:74(create_fetcher)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:482(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        1    0.000    0.000    0.644    0.644 fetch.py:46(fetch)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:497(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:403(WORLD)\n",
      "        5    0.000    0.000    0.000    0.000 hacks.py:26(_check_iterable)\n",
      "        1    0.000    0.000    0.001    0.001 dataloader.py:383(_get_iterator)\n",
      "        1    0.000    0.000    0.006    0.006 collate.py:142(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:7(is_available)\n",
      "        5    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\n",
      "        1    0.000    0.000    0.006    0.006 collate.py:204(default_collate)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        1    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)\n",
      "        1    0.000    0.000    0.000    0.000 fetch.py:8(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 dataloader.py:428(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:306(inner)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:110(num_samples)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:323(default_pg)\n",
      "        2    0.000    0.000    0.000    0.000 3599899832.py:21(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _collections_abc.py:315(__subclasshook__)\n",
      "        1    0.000    0.000    0.001    0.001 dataloader.py:622(_next_index)\n",
      "        2    0.000    0.000    0.000    0.000 worker.py:89(get_worker_info)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:443(_auto_collation)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:89(annotate)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:447(_index_sampler)\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile.run(\"next(iter(pytorch_dl))\", sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.000    0.000 base_iterator.py:450(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 pytorch.py:203(__next__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile.run(\"next(iter(labelled_loader))\", sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637 ms ± 47.3 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5\n",
    "next(iter(pytorch_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.7 ms ± 1.27 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5\n",
    "next(iter(labelled_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d839c22a2c74e118c21fef61a06ce2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(labelled_loader, total=len(pytorch_dl)):\n",
    "    continue\n",
    "\n",
    "labelled_loader.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f093cdeb061423b984f4f46efd0ff02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(pytorch_dl, total=len(pytorch_dl)):\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - DALI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (gt.argmax(dim=-1)==pred).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/image-dali'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for epoch in tqdm(range(1), leave=True):\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "        \n",
    "        for i, (labelled_data) in enumerate(tqdm(labelled_loader, total=len(pytorch_dl), leave=False)):\n",
    "            # lab, unlab = batch\n",
    "            inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "            inp = inp.to(DEVICE)\n",
    "            y = y.reshape(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inp)\n",
    "\n",
    "            loss = F.cross_entropy(outputs, y)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            prof.step()\n",
    "        \n",
    "        # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "        # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "        labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5fb702b7124a65a7968d5c66948ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d96187a058f4b08ac05a61eeb46cdb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (ft.argmax(dim=)).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1), leave=True):\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    for i, (labelled_data) in enumerate(tqdm(labelled_loader, total=len(pytorch_dl), leave=False)):\n",
    "        # lab, unlab = batch\n",
    "        inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "        inp = inp.to(DEVICE)\n",
    "        y = y.reshape(-1).to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inp)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, y)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "    # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "    labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Native Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': precision_score}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/image-pytorch'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for epoch in tqdm(range(1), leave=True):\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        # epoch_test_loss = 0\n",
    "        \n",
    "        for i, (labelled_data) in enumerate(tqdm(pytorch_dl, total=len(pytorch_dl), leave=False)):\n",
    "            # lab, unlab = batch\n",
    "            # inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "            inp, y = labelled_data\n",
    "            inp = inp.to(DEVICE)\n",
    "            y = y.reshape(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inp)\n",
    "\n",
    "            loss = F.cross_entropy(outputs, y)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            prof.step()\n",
    "        \n",
    "        # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "        # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "        # labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05573fc40c0e4c9aa0a94d70f82fb2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bd73c026cf4cb49eecfa77d8568a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (ft.argmax(dim=)).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1), leave=True):\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    for i, (labelled_data) in enumerate(tqdm(pytorch_dl, total=len(pytorch_dl), leave=False)):\n",
    "        \n",
    "        inp, y = labelled_data\n",
    "        inp = inp.to(DEVICE)\n",
    "        y = y.reshape(-1).to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inp)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, y)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "    # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "    # labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Pytorch Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (gt.argmax(dim=-1)==pred).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/dali-expanded'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for epoch in tqdm(range(1), leave=True):\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "        \n",
    "        for i, (labelled_data) in enumerate(tqdm(labelled_loader, total=len(pytorch_dl), leave=False)):\n",
    "            # lab, unlab = batch\n",
    "            inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "            inp = inp.to(DEVICE)\n",
    "            y = y.reshape(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inp)\n",
    "\n",
    "            loss = F.cross_entropy(outputs, y)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            prof.step()\n",
    "        \n",
    "        # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "        # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "        labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
