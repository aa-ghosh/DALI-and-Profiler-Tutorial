{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL FOR DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, WeightedRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import cv2\n",
    "import cProfile as profile\n",
    "\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator as PyTorchIterator\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator as GenIterator\n",
    "from nvidia.dali.plugin.pytorch import LastBatchPolicy\n",
    "import math\n",
    "\n",
    "DEVICE = 'cuda:1'\n",
    "DEVICE = DEVICE if torch.cuda.is_available() else 'cpu'\n",
    "THREADS = 1\n",
    "LOGSDIR = './runs'\n",
    "# DATADIR = Path('./data')\n",
    "IMAGE_DATA = '../imagenet/ILSVRC/Data/CLS-LOC/'\n",
    "EPOCHS = 300\n",
    "BATCHSIZE = 64\n",
    "# MU = 7\n",
    "TOTAL_ITERS = None\n",
    "NUMWORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import AutoLogger\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data\n",
    "DATADIR = Path('../semisupervisedMM/data')\n",
    "IMAGE_DATA = '../imagenet/ILSVRC/Data/CLS-LOC/'\n",
    "datapath = Path(IMAGE_DATA)\n",
    "imagepath = datapath/'train'\n",
    "validpath = datapath/'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled = pd.read_csv(DATADIR/'labelled.csv')\n",
    "test = pd.read_csv(DATADIR/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    def __init__(self, path, df, weak_trans, \n",
    "            batch_size, label_list=None, total_len=0, shuffle=False):\n",
    "        self.df = df\n",
    "        # self.labelled = is_labelled\n",
    "        self.total_len = total_len\n",
    "        # self.strong_trans = strong_trans\n",
    "        self.weak_trans = weak_trans\n",
    "        self.path = Path(path)\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.label_list = label_list\n",
    "        # if self.labelled:\n",
    "        if not self.label_list:\n",
    "            self.label_list = self.df.label.unique().tolist()\n",
    "        class_w = (self.df.shape[0]/self.df.label.value_counts())\n",
    "        # print(class_w)\n",
    "\n",
    "        self.weights = self.df.label.apply(lambda x: class_w[x]).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.indices = list(range(len(self)))\n",
    "        if self.shuffle:\n",
    "            shuffle(self.indices)\n",
    "        self.total_batches = 0\n",
    "        self.i = 0\n",
    "        self.n = len(self)\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        batch_2 = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            if (self.i == self.n) and (not self.total_len):\n",
    "                self.__iter__()\n",
    "                raise StopIteration()\n",
    "            \n",
    "            \n",
    "            row = self.df.iloc[self.indices[self.i]]\n",
    "            image = row.path\n",
    "            \n",
    "            f = open(self.path/image, 'rb')\n",
    "            img = (np.frombuffer(f.read(), dtype=np.uint8))    \n",
    "            batch.append(img)\n",
    "            f.close()\n",
    "\n",
    "            batch_2.append(np.array([self.label_list.index(row.label)]))\n",
    "            self.i = (self.i+1)\n",
    "            self.total_batches += 1\n",
    "            if (self.i == self.n) and (not self.total_len):\n",
    "                self.__iter__()\n",
    "                raise StopIteration()\n",
    "            elif (self.total_len) and (self.total_batches == self.total_len):\n",
    "                self.__iter__()\n",
    "                raise StopIteration()\n",
    "            self.i = self.i%self.n\n",
    "        \n",
    "        return (batch, batch_2)\n",
    "            \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = row.path\n",
    "        \n",
    "        image = Image.open(self.path/image).convert('RGB')\n",
    "        # image = cv2.cvtColor(cv2.imread(str(self.path/image)), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "\n",
    "        # if self.labelled:\n",
    "        X = self.weak_trans(image)\n",
    "        image.close()\n",
    "        y = self.label_list.index(row.label)\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "\n",
    "weak_trans = transforms.Compose([\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomPerspective(0.05),\n",
    "    transforms.RandomResizedCrop(224, (0.8, 1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dali_weak_aug(image):\n",
    "    image = fn.rotate(image, angle=fn.random.uniform(range=(0,5)))\n",
    "    image = fn.random_resized_crop(image, size=(224,224), \n",
    "                                   random_area=(0.8,1))\n",
    "    image = fn.flip(image, horizontal=fn.random.coin_flip())\n",
    "    image = fn.color_twist(image, brightness=fn.random.uniform(range=(0.8,1.2)),\n",
    "                        contrast=fn.random.uniform(range=(0.8,1.2)),\n",
    "                        saturation=fn.random.uniform(range=(0.9,1)))\n",
    "    image = fn.crop_mirror_normalize(image, \n",
    "                                mean=[123.6750, 116.2800, 103.5300], \n",
    "                                std=[58.3950, 57.1200, 57.3750],\n",
    "                                dtype=types.FLOAT)\n",
    "    return image\n",
    "\n",
    "\n",
    "def ExternalLabelledSourcePipeline(batch_size, num_threads, device_id, external_data):\n",
    "    pipe = Pipeline(batch_size, num_threads, device_id)\n",
    "    with pipe:\n",
    "        jpegs, labels = fn.external_source(source=external_data, num_outputs=2, \n",
    "                                           dtype=[types.UINT8, types.INT64])\n",
    "        images = fn.decoders.image(jpegs, device=\"mixed\")\n",
    "        images = dali_weak_aug(images)\n",
    "        pipe.set_outputs(images, labels)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_iterator = SupervisedDataset(imagepath, df=labelled, \n",
    "                                        weak_trans=weak_trans, batch_size=BATCHSIZE, \n",
    "                                        total_len=None, shuffle=True)\n",
    "\n",
    "pytorch_dl = DataLoader(labelled_iterator, batch_size=BATCHSIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "pipe_labelled = ExternalLabelledSourcePipeline(batch_size=BATCHSIZE, num_threads=THREADS, device_id = int(DEVICE.split(':')[-1]),\n",
    "                              external_data = labelled_iterator)\n",
    "\n",
    "labelled_loader = GenIterator(pipe_labelled, output_map=['x', 'y'], \n",
    "                      last_batch_padded=True, last_batch_policy=LastBatchPolicy.PARTIAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         82483 function calls (82073 primitive calls) in 0.711 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      132    0.180    0.001    0.180    0.001 {method 'decode' of 'ImagingDecoder' objects}\n",
      "       98    0.161    0.002    0.161    0.002 {method 'transform2' of 'ImagingCore' objects}\n",
      "       10    0.083    0.008    0.083    0.008 {built-in method marshal.loads}\n",
      "       64    0.064    0.001    0.064    0.001 {method 'resize' of 'ImagingCore' objects}\n",
      "      192    0.050    0.000    0.050    0.000 {built-in method PIL._imaging.blend}\n",
      "      226    0.014    0.000    0.014    0.000 {built-in method PIL._imaging.fill}\n",
      "       64    0.012    0.000    0.012    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
      "       64    0.008    0.000    0.008    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
      "      258    0.008    0.000    0.008    0.000 {method 'convert' of 'ImagingCore' objects}\n",
      "      126    0.007    0.000    0.007    0.000 {method 'copy' of 'ImagingCore' objects}\n",
      "       64    0.006    0.000    0.006    0.000 {built-in method io.open}\n",
      "        2    0.005    0.003    0.005    0.003 {built-in method torch.stack}\n",
      "       64    0.005    0.000    0.005    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "       34    0.004    0.000    0.004    0.000 {built-in method torch._C._linalg.linalg_lstsq}\n",
      "       64    0.004    0.000    0.004    0.000 {method 'crop' of 'ImagingCore' objects}\n",
      "       64    0.003    0.000    0.008    0.000 transforms.py:927(get_params)\n",
      "       64    0.002    0.000    0.002    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
      "        1    0.002    0.002    0.711    0.711 <string>:1(<module>)\n",
      "      434    0.002    0.000    0.002    0.000 {built-in method torch.tensor}\n",
      "       64    0.002    0.000    0.071    0.001 transforms.py:1267(forward)\n",
      "       34    0.002    0.000    0.008    0.000 functional.py:687(_get_perspective_coeffs)\n",
      "     2566    0.002    0.000    0.002    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "      946    0.002    0.000    0.002    0.000 {built-in method torch.empty}\n",
      "       64    0.002    0.000    0.002    0.000 {built-in method PIL._imaging.new}\n",
      "       64    0.002    0.000    0.002    0.000 {method 'histogram' of 'ImagingCore' objects}\n",
      "      944    0.002    0.000    0.002    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
      "       64    0.002    0.000    0.002    0.000 {method 'sub_' of 'torch._C._TensorBase' objects}\n",
      "       64    0.002    0.000    0.002    0.000 {method 'div_' of 'torch._C._TensorBase' objects}\n",
      "       64    0.001    0.000    0.002    0.000 ImageStat.py:77(_getsum)\n",
      "     1016    0.001    0.000    0.002    0.000 utils.py:538(_log_api_usage_once)\n",
      "       64    0.001    0.000    0.167    0.003 transforms.py:793(forward)\n",
      "      126    0.001    0.000    0.186    0.001 ImageFile.py:155(load)\n",
      "      952    0.001    0.000    0.002    0.000 Image.py:543(_new)\n",
      "      448    0.001    0.000    0.001    0.000 {built-in method posix.lstat}\n",
      "9462/9457    0.001    0.000    0.002    0.000 {built-in method builtins.isinstance}\n",
      "      192    0.001    0.000    0.001    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
      "        2    0.001    0.001    0.001    0.001 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "      448    0.001    0.000    0.359    0.001 module.py:1494(_call_impl)\n",
      "       64    0.001    0.000    0.004    0.000 {built-in method numpy.array}\n",
      "      368    0.001    0.000    0.001    0.000 {built-in method torch.randint}\n",
      "       64    0.001    0.000    0.008    0.000 _functional_tensor.py:905(normalize)\n",
      "       64    0.001    0.000    0.004    0.000 JpegImagePlugin.py:351(_open)\n",
      "       64    0.001    0.000    0.031    0.000 functional.py:125(to_tensor)\n",
      "       22    0.001    0.000    0.001    0.000 {method 'transpose' of 'ImagingCore' objects}\n",
      "     1242    0.001    0.000    0.001    0.000 Image.py:512(__init__)\n",
      "      320    0.001    0.000    0.201    0.001 Image.py:889(convert)\n",
      "     1496    0.001    0.000    0.001    0.000 Image.py:835(load)\n",
      "       64    0.001    0.000    0.700    0.011 3599899832.py:65(__getitem__)\n",
      "       64    0.001    0.000    0.002    0.000 transforms.py:711(forward)\n",
      "      128    0.001    0.000    0.001    0.000 {built-in method torch.rand}\n",
      "       78    0.001    0.000    0.001    0.000 {method 'join' of 'bytes' objects}\n",
      "       64    0.001    0.000    0.003    0.000 posixpath.py:401(_joinrealpath)\n",
      "     1016    0.001    0.000    0.001    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "       64    0.001    0.000    0.391    0.006 transforms.py:93(__call__)\n",
      "      512    0.001    0.000    0.001    0.000 posixpath.py:71(join)\n",
      "      226    0.001    0.000    0.001    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "       10    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:179(_get_module_lock)\n",
      "       65    0.001    0.000    0.001    0.000 {built-in method torch.randperm}\n",
      "      128    0.001    0.000    0.070    0.001 functional.py:391(resize)\n",
      "      128    0.001    0.000    0.001    0.000 {built-in method torch.as_tensor}\n",
      "      128    0.001    0.000    0.001    0.000 pathlib.py:56(parse_parts)\n",
      "      344    0.001    0.000    0.001    0.000 {built-in method torch.exp}\n",
      "     1122    0.001    0.000    0.001    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "      959    0.001    0.000    0.001    0.000 {built-in method builtins.round}\n",
      "      320    0.001    0.000    0.003    0.000 functional.py:64(get_dimensions)\n",
      "     1016    0.001    0.000    0.001    0.000 _trace.py:1101(is_tracing)\n",
      "       64    0.001    0.000    0.022    0.000 Image.py:2227(rotate)\n",
      "       64    0.001    0.000    0.001    0.000 {built-in method torch.log}\n",
      "      128    0.000    0.000    0.067    0.001 Image.py:2089(resize)\n",
      "      126    0.000    0.000    0.001    0.000 JpegImagePlugin.py:243(DQT)\n",
      "      320    0.000    0.000    0.001    0.000 _functional_pil.py:22(get_dimensions)\n",
      "       64    0.000    0.000    0.006    0.000 Image.py:3242(_open_core)\n",
      "       64    0.000    0.000    0.010    0.000 ImageEnhance.py:65(__init__)\n",
      "      126    0.000    0.000    0.000    0.000 JpegImagePlugin.py:263(<listcomp>)\n",
      "      512    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "      226    0.000    0.000    0.015    0.000 Image.py:2896(new)\n",
      "       81    0.000    0.000    0.001    0.000 JpegImagePlugin.py:61(APP)\n",
      "       98    0.000    0.000    0.001    0.000 _functional_pil.py:253(_parse_fill)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'any' of 'torch._C._TensorBase' objects}\n",
      "      674    0.000    0.000    0.001    0.000 Image.py:1312(getbands)\n",
      "      876    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "     1827    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "3532/3458    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'unbind' of 'torch._C._TensorBase' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
      "       64    0.000    0.000    0.105    0.002 Image.py:3174(open)\n",
      "       98    0.000    0.000    0.176    0.002 Image.py:2629(transform)\n",
      "       98    0.000    0.000    0.162    0.002 Image.py:2719(__transformer)\n",
      "     1050    0.000    0.000    0.000    0.000 _functional_pil.py:14(_is_pil_image)\n",
      "       64    0.000    0.000    0.001    0.000 posixpath.py:338(normpath)\n",
      "      192    0.000    0.000    0.003    0.000 generic.py:5888(__getattr__)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method _functools.reduce}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
      "      738    0.000    0.000    0.000    0.000 ImageMode.py:36(getmode)\n",
      "       34    0.000    0.000    0.001    0.000 transforms.py:815(get_params)\n",
      "       64    0.000    0.000    0.003    0.000 Image.py:729(tobytes)\n",
      "       64    0.000    0.000    0.003    0.000 frame.py:3703(_ixs)\n",
      "       64    0.000    0.000    0.000    0.000 JpegImagePlugin.py:193(SOF)\n",
      "     1513    0.000    0.000    0.001    0.000 _binary.py:80(i16be)\n",
      "       64    0.000    0.000    0.001    0.000 transforms.py:1235(get_params)\n",
      "       94    0.000    0.000    0.001    0.000 {built-in method posix.stat}\n",
      "       64    0.000    0.000    0.001    0.000 Image.py:572(close)\n",
      "      739    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       35    0.000    0.000    0.000    0.000 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
      "      590    0.000    0.000    0.000    0.000 ImageFile.py:555(_safe_read)\n",
      "     1590    0.000    0.000    0.000    0.000 {built-in method _struct.unpack_from}\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:5844(__finalize__)\n",
      "      128    0.000    0.000    0.001    0.000 series.py:966(__getitem__)\n",
      "       64    0.000    0.000    0.008    0.000 functional.py:340(normalize)\n",
      "      128    0.000    0.000    0.001    0.000 pathlib.py:569(_parse_args)\n",
      "      128    0.000    0.000    0.000    0.000 base.py:5254(__contains__)\n",
      "       64    0.000    0.000    0.001    0.000 managers.py:1078(fast_xs)\n",
      "     1016    0.000    0.000    0.000    0.000 {built-in method torch._C._is_tracing}\n",
      "       64    0.000    0.000    0.004    0.000 ImageFile.py:88(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method torch.from_numpy}\n",
      "       64    0.000    0.000    0.004    0.000 indexing.py:1592(_getitem_axis)\n",
      "       31    0.000    0.000    0.001    0.000 {built-in method builtins.__build_class__}\n",
      "       64    0.000    0.000    0.023    0.000 functional.py:1074(rotate)\n",
      "       64    0.000    0.000    0.001    0.000 transforms.py:1352(get_params)\n",
      "      128    0.000    0.000    0.067    0.001 _functional_pil.py:238(resize)\n",
      "      316    0.000    0.000    0.001    0.000 JpegImagePlugin.py:56(Skip)\n",
      "     1432    0.000    0.000    0.000    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
      "        1    0.000    0.000    0.700    0.700 fetch.py:51(<listcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method io.open_code}\n",
      "      192    0.000    0.000    0.051    0.000 Image.py:3305(blend)\n",
      "   192/64    0.000    0.000    0.003    0.000 ImageStat.py:43(__getattr__)\n",
      "       34    0.000    0.000    0.164    0.005 functional.py:715(perspective)\n",
      "      192    0.000    0.000    0.000    0.000 pathlib.py:621(__str__)\n",
      "       64    0.000    0.000    0.004    0.000 Image.py:1236(_crop)\n",
      "     2456    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "     2033    0.000    0.000    0.000    0.000 _jit_internal.py:1102(is_scripting)\n",
      "      768    0.000    0.000    0.000    0.000 {built-in method sys.intern}\n",
      "       64    0.000    0.000    0.001    0.000 blocks.py:2172(new_block)\n",
      "       34    0.000    0.000    0.000    0.000 {built-in method torch.zeros}\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:259(__init__)\n",
      "     1634    0.000    0.000    0.000    0.000 Image.py:539(size)\n",
      "      226    0.000    0.000    0.000    0.000 Image.py:2875(_check_size)\n",
      "     1050    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       64    0.000    0.000    0.001    0.000 ImageStat.py:69(_getcount)\n",
      "       64    0.000    0.000    0.026    0.000 transforms.py:1362(forward)\n",
      "       64    0.000    0.000    0.071    0.001 functional.py:610(resized_crop)\n",
      "      128    0.000    0.000    0.000    0.000 base.py:5934(_get_values_for_loc)\n",
      "      128    0.000    0.000    0.001    0.000 generic.py:5904(__setattr__)\n",
      "      384    0.000    0.000    0.000    0.000 Image.py:525(__getattr__)\n",
      "       64    0.000    0.000    0.000    0.000 Image.py:417(_getencoder)\n",
      "       64    0.000    0.000    0.002    0.000 ImageStat.py:30(__init__)\n",
      "       64    0.000    0.000    0.001    0.000 pathlib.py:615(_make_child)\n",
      "       64    0.000    0.000    0.006    0.000 pathlib.py:1064(resolve)\n",
      "      128    0.000    0.000    0.001    0.000 series.py:1072(_get_value)\n",
      "       64    0.000    0.000    0.005    0.000 JpegImagePlugin.py:821(jpeg_factory)\n",
      "       64    0.000    0.000    0.079    0.001 transforms.py:971(forward)\n",
      "      126    0.000    0.000    0.008    0.000 Image.py:1197(copy)\n",
      "      128    0.000    0.000    0.000    0.000 managers.py:2069(internal_values)\n",
      "       64    0.000    0.000    0.002    0.000 ImageStat.py:99(_getmean)\n",
      "      128    0.000    0.000    0.000    0.000 common.py:162(is_object_dtype)\n",
      "      162    0.000    0.000    0.000    0.000 _functional_pil.py:41(get_image_num_channels)\n",
      "       64    0.000    0.000    0.000    0.000 Image.py:393(_getdecoder)\n",
      "       64    0.000    0.000    0.023    0.000 _functional_pil.py:298(rotate)\n",
      "       64    0.000    0.000    0.003    0.000 Image.py:687(__array_interface__)\n",
      "       64    0.000    0.000    0.005    0.000 ImageEnhance.py:48(__init__)\n",
      "       64    0.000    0.000    0.005    0.000 indexing.py:1059(__getitem__)\n",
      "      192    0.000    0.000    0.000    0.000 indexing.py:2656(check_deprecated_indexers)\n",
      "      640    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
      "       64    0.000    0.000    0.018    0.000 functional.py:876(adjust_brightness)\n",
      "       64    0.000    0.000    0.022    0.000 functional.py:920(adjust_saturation)\n",
      "     38/2    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "       64    0.000    0.000    0.027    0.000 functional.py:898(adjust_contrast)\n",
      "      128    0.000    0.000    0.000    0.000 base.py:3754(get_loc)\n",
      "      128    0.000    0.000    0.001    0.000 base.py:2581(is_object)\n",
      "       64    0.000    0.000    0.000    0.000 blocks.py:2120(get_block_type)\n",
      "       64    0.000    0.000    0.000    0.000 Image.py:248(_conv_type_shape)\n",
      "       64    0.000    0.000    0.001    0.000 _tensor.py:920(__iter__)\n",
      "      142    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x743500}\n",
      "       64    0.000    0.000    0.001    0.000 series.py:342(__init__)\n",
      "       64    0.000    0.000    0.001    0.000 posixpath.py:377(abspath)\n",
      "      990    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "       64    0.000    0.000    0.005    0.000 posixpath.py:392(realpath)\n",
      "       64    0.000    0.000    0.001    0.000 ImageEnhance.py:82(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
      "      226    0.000    0.000    0.000    0.000 enum.py:783(__hash__)\n",
      "       64    0.000    0.000    0.000    0.000 ImageFile.py:229(<listcomp>)\n",
      "       64    0.000    0.000    0.004    0.000 Image.py:1210(crop)\n",
      "      128    0.000    0.000    0.001    0.000 base.py:5363(_can_hold_identifiers_and_holds_name)\n",
      "      128    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "      128    0.000    0.000    0.000    0.000 common.py:1591(_is_dtype_type)\n",
      "      192    0.000    0.000    0.051    0.000 ImageEnhance.py:25(enhance)\n",
      "      192    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
      "       64    0.000    0.000    0.005    0.000 functional.py:544(crop)\n",
      "       64    0.000    0.000    0.027    0.000 _functional_pil.py:77(adjust_contrast)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_operation_overload}\n",
      "      128    0.000    0.000    0.000    0.000 pathlib.py:608(_format_parsed_parts)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method PIL._imaging.jpeg_decoder}\n",
      "      128    0.000    0.000    0.000    0.000 pathlib.py:239(splitroot)\n",
      "      193    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "      128    0.000    0.000    0.000    0.000 posixpath.py:60(isabs)\n",
      "      132    0.000    0.000    0.002    0.000 JpegImagePlugin.py:404(load_read)\n",
      "       34    0.000    0.000    0.156    0.005 _functional_pil.py:315(perspective)\n",
      "       64    0.000    0.000    0.031    0.000 transforms.py:129(__call__)\n",
      "       64    0.000    0.000    0.000    0.000 managers.py:1891(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 blocks.py:2091(maybe_coerce_values)\n",
      "      512    0.000    0.000    0.000    0.000 {method 'partition' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 common.py:96(is_bool_indexer)\n",
      "       64    0.000    0.000    0.000    0.000 series.py:611(name)\n",
      "      392    0.000    0.000    0.000    0.000 _functional_pil.py:275(<genexpr>)\n",
      "       64    0.000    0.000    0.000    0.000 blocks.py:2186(check_ndim)\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:564(_get_axis)\n",
      "       64    0.000    0.000    0.000    0.000 series.py:661(name)\n",
      "       64    0.000    0.000    0.018    0.000 _functional_pil.py:67(adjust_brightness)\n",
      "       64    0.000    0.000    0.002    0.000 ImageFile.py:292(load_prepare)\n",
      "       64    0.000    0.000    0.022    0.000 _functional_pil.py:87(adjust_saturation)\n",
      "       64    0.000    0.000    0.000    0.000 blocks.py:827(iget)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:180(__new__)\n",
      "      526    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 indexing.py:1539(_validate_integer)\n",
      "       65    0.000    0.000    0.001    0.000 sampler.py:117(__iter__)\n",
      "      128    0.000    0.000    0.000    0.000 Image.py:3153(_decompression_bomb_check)\n",
      "      688    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "       64    0.000    0.000    0.009    0.000 transforms.py:269(forward)\n",
      "       64    0.000    0.000    0.000    0.000 range.py:956(__getitem__)\n",
      "      192    0.000    0.000    0.000    0.000 generic.py:40(_check)\n",
      "      272    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "       64    0.000    0.000    0.004    0.000 _functional_pil.py:223(crop)\n",
      "        1    0.000    0.000    0.706    0.706 dataloader.py:675(_next_data)\n",
      "      192    0.000    0.000    0.000    0.000 generic.py:45(_instancecheck)\n",
      "      128    0.000    0.000    0.000    0.000 functional.py:366(_compute_resized_output_size)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1536(find_spec)\n",
      "      411    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:1(<module>)\n",
      "      128    0.000    0.000    0.000    0.000 series.py:708(_values)\n",
      "      128    0.000    0.000    0.000    0.000 managers.py:275(arrays)\n",
      "      420    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "      128    0.000    0.000    0.000    0.000 pathlib.py:631(__fspath__)\n",
      "      128    0.000    0.000    0.000    0.000 generic.py:640(_info_axis)\n",
      "      128    0.000    0.000    0.000    0.000 functional.py:1596(_check_antialias)\n",
      "       64    0.000    0.000    0.003    0.000 transforms.py:353(forward)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method PIL._imaging.raw_encoder}\n",
      "       64    0.000    0.000    0.002    0.000 Image.py:1597(histogram)\n",
      "       64    0.000    0.000    0.000    0.000 JpegImagePlugin.py:512(_getmp)\n",
      "       64    0.000    0.000    0.000    0.000 flags.py:85(allows_duplicate_labels)\n",
      "       78    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "       34    0.000    0.000    0.000    0.000 ImageMode.py:25(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:921(_find_spec)\n",
      "       64    0.000    0.000    0.001    0.000 pathlib.py:589(_from_parts)\n",
      "       10    0.000    0.000    0.084    0.008 <frozen importlib._bootstrap_external>:950(get_code)\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method math.cos}\n",
      "       64    0.000    0.000    0.000    0.000 flags.py:49(__init__)\n",
      "      192    0.000    0.000    0.000    0.000 common.py:362(apply_if_callable)\n",
      "       64    0.000    0.000    0.000    0.000 pathlib.py:600(_from_parsed_parts)\n",
      "      128    0.000    0.000    0.000    0.000 base.py:163(array)\n",
      "       64    0.000    0.000    0.000    0.000 common.py:1725(validate_all_hashable)\n",
      "       64    0.000    0.000    0.000    0.000 __init__.py:1455(debug)\n",
      "      128    0.000    0.000    0.000    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
      "      448    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
      "      128    0.000    0.000    0.000    0.000 common.py:146(classes)\n",
      "       64    0.000    0.000    0.000    0.000 BmpImagePlugin.py:55(_dib_accept)\n",
      "      242    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "      128    0.000    0.000    0.000    0.000 common.py:1744(<genexpr>)\n",
      "       64    0.000    0.000    0.000    0.000 construction.py:461(ensure_wrapped_if_datetimelike)\n",
      "      384    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "       64    0.000    0.000    0.000    0.000 Image.py:2315(transform)\n",
      "       20    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:380(cache_from_source)\n",
      "      104    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        1    0.000    0.000    0.084    0.084 JpegImagePlugin.py:1(<module>)\n",
      "       64    0.000    0.000    0.001    0.000 pathlib.py:853(__truediv__)\n",
      "       64    0.000    0.000    0.000    0.000 indexing.py:139(iloc)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'setimage' of 'ImagingDecoder' objects}\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:550(_get_axis_number)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:222(<setcomp>)\n",
      "       22    0.000    0.000    0.001    0.000 functional.py:667(hflip)\n",
      "       64    0.000    0.000    0.000    0.000 __init__.py:1724(isEnabledFor)\n",
      "       64    0.000    0.000    0.000    0.000 _functional_tensor.py:9(_is_tensor_a_torch_image)\n",
      "      359    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "       64    0.000    0.000    0.087    0.001 Image.py:321(preinit)\n",
      "       65    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "      128    0.000    0.000    0.000    0.000 managers.py:287(<listcomp>)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:332(attrs)\n",
      "       66    0.000    0.000    0.000    0.000 range.py:946(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "       64    0.000    0.000    0.000    0.000 pathlib.py:94(join_parsed_parts)\n",
      "     10/5    0.000    0.000    0.087    0.017 <frozen importlib._bootstrap>:1022(_find_and_load)\n",
      "       64    0.000    0.000    0.000    0.000 functional.py:115(_is_numpy)\n",
      "       64    0.000    0.000    0.000    0.000 TiffImagePlugin.py:272(_accept)\n",
      "      128    0.000    0.000    0.000    0.000 common.py:148(<lambda>)\n",
      "       64    0.000    0.000    0.000    0.000 _binary.py:60(i32le)\n",
      "       20    0.000    0.000    0.000    0.000 enum.py:89(__setitem__)\n",
      "       64    0.000    0.000    0.000    0.000 pathlib.py:1092(stat)\n",
      "       64    0.000    0.000    0.000    0.000 BmpImagePlugin.py:51(_accept)\n",
      "       64    0.000    0.000    0.000    0.000 _functional_tensor.py:13(_assert_image_tensor)\n",
      "       22    0.000    0.000    0.001    0.000 Image.py:2798(transpose)\n",
      "      128    0.000    0.000    0.000    0.000 Image.py:535(height)\n",
      "      128    0.000    0.000    0.000    0.000 JpegImagePlugin.py:337(_accept)\n",
      "       64    0.000    0.000    0.000    0.000 inference.py:325(is_hashable)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method torch.get_default_dtype}\n",
      "     10/5    0.000    0.000    0.087    0.017 <frozen importlib._bootstrap>:664(_load_unlocked)\n",
      "       64    0.000    0.000    0.000    0.000 _util.py:5(is_path)\n",
      "       64    0.000    0.000    0.000    0.000 JpegImagePlugin.py:487(_getmp)\n",
      "      216    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:492(_init_module_attrs)\n",
      "       60    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:126(_path_join)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:494(_parse)\n",
      "      128    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method math.sin}\n",
      "       60    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:128(<listcomp>)\n",
      "        1    0.000    0.000    0.002    0.002 dataloader.py:567(__init__)\n",
      "     11/1    0.000    0.000    0.711    0.711 {built-in method builtins.exec}\n",
      "      128    0.000    0.000    0.000    0.000 Image.py:531(width)\n",
      "     10/5    0.000    0.000    0.087    0.017 <frozen importlib._bootstrap>:987(_find_and_load_unlocked)\n",
      "       64    0.000    0.000    0.000    0.000 _util.py:15(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 inference.py:188(is_array_like)\n",
      "       22    0.000    0.000    0.001    0.000 _functional_pil.py:51(hflip)\n",
      "        1    0.000    0.000    0.001    0.001 PngImagePlugin.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler.}\n",
      "     13/5    0.000    0.000    0.087    0.017 <frozen importlib._bootstrap>:1053(_handle_fromlist)\n",
      "       64    0.000    0.000    0.000    0.000 GifImagePlugin.py:54(_accept)\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:4114(_set_is_copy)\n",
      "       65    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:404(parent)\n",
      "       64    0.000    0.000    0.000    0.000 common.py:1420(is_1d_only_ea_dtype)\n",
      "       64    0.000    0.000    0.000    0.000 managers.py:2433(_using_copy_on_write)\n",
      "       23    0.000    0.000    0.000    0.000 enum.py:470(__setattr__)\n",
      "       10    0.000    0.000    0.083    0.008 <frozen importlib._bootstrap_external>:670(_compile_bytecode)\n",
      "       10    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 JpegPresets.py:1(<module>)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:721(spec_from_file_location)\n",
      "       64    0.000    0.000    0.000    0.000 utils.py:66(is_list_like_indexer)\n",
      "      3/1    0.000    0.000    0.006    0.006 collate.py:87(collate)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_init}\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1070(get_data)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:125(release)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
      "     10/5    0.000    0.000    0.086    0.017 <frozen importlib._bootstrap_external>:877(exec_module)\n",
      "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:430(ImageFileDirectory_v2)\n",
      "      128    0.000    0.000    0.000    0.000 generic.py:353(flags)\n",
      "        1    0.000    0.000    0.001    0.001 BmpImagePlugin.py:1(<module>)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method math.radians}\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:239(__init__)\n",
      "      192    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'cleanup' of 'ImagingDecoder' objects}\n",
      "       70    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:244(_verbose_message)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1399(_get_spec)\n",
      "        9    0.000    0.000    0.000    0.000 TiffImagePlugin.py:686(_register_basic)\n",
      "       20    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:132(_path_split)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 GifImagePlugin.py:1(<module>)\n",
      "      115    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 ImageFile.py:1(<module>)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "      4/2    0.000    0.000    0.000    0.000 sre_compile.py:87(_compile)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:100(acquire)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:495(__exit__)\n",
      "       64    0.000    0.000    0.000    0.000 ImageFile.py:232(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "      128    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
      "      9/5    0.000    0.000    0.087    0.017 {built-in method builtins.__import__}\n",
      "       30    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:84(_unpack_uint32)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:165(__prepare__)\n",
      "        6    0.000    0.000    0.000    0.000 enum.py:590(_find_data_type)\n",
      "      128    0.000    0.000    0.000    0.000 base.py:6569(_maybe_cast_indexer)\n",
      "    68/67    0.000    0.000    0.002    0.000 {built-in method builtins.iter}\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:146(_type_check)\n",
      "       64    0.000    0.000    0.000    0.000 collate.py:137(<genexpr>)\n",
      "       64    0.000    0.000    0.000    0.000 flags.py:53(allows_duplicate_labels)\n",
      "       20    0.000    0.000    0.000    0.000 enum.py:44(_is_private)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:564(module_from_spec)\n",
      "      114    0.000    0.000    0.000    0.000 TiffImagePlugin.py:260(<genexpr>)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:585(_classify_pyc)\n",
      "       64    0.000    0.000    0.000    0.000 ImageFile.py:75(_tilesort)\n",
      "       64    0.000    0.000    0.000    0.000 managers.py:2009(_block)\n",
      "       64    0.000    0.000    0.000    0.000 ImageFile.py:300(load_end)\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        1    0.000    0.000    0.706    0.706 dataloader.py:628(__next__)\n",
      "       64    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:447(__getattr__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:510(_get_cached)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:71(__init__)\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1531(_get_spec)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1016(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:1(<module>)\n",
      "        8    0.000    0.000    0.000    0.000 typing.py:986(__setattr__)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:1315(getLogger)\n",
      "       30    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:140(_path_stat)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:944(parse)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:626(_find_new_)\n",
      "     67/1    0.000    0.000    0.706    0.706 {built-in method builtins.next}\n",
      "      140    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:198(cb)\n",
      "        5    0.000    0.000    0.000    0.000 sre_compile.py:292(_optimize_charset)\n",
      "       64    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "        2    0.000    0.000    0.000    0.000 re.py:288(_compile)\n",
      "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:669(decorator)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:560(_compile_info)\n",
      "       20    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:391(cached)\n",
      "        7    0.000    0.000    0.000    0.000 Image.py:3392(register_open)\n",
      "      4/2    0.000    0.000    0.000    0.000 sre_parse.py:175(getwidth)\n",
      "       20    0.000    0.000    0.000    0.000 enum.py:22(_is_dunder)\n",
      "       40    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:134(<genexpr>)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:2071(getLogger)\n",
      "       40    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:893(__enter__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1431(find_spec)\n",
      "       10    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:169(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:783(compile)\n",
      "       15    0.000    0.000    0.000    0.000 Image.py:3441(register_extension)\n",
      "       20    0.000    0.000    0.000    0.000 enum.py:33(_is_sunder)\n",
      "     19/5    0.000    0.000    0.087    0.017 <frozen importlib._bootstrap>:233(_call_with_frames_removed)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:618(_validate_timestamp_pyc)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "     38/2    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)\n",
      "        2    0.000    0.000    0.006    0.003 collate.py:153(collate_tensor_fn)\n",
      "       40    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:897(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:542(_check_name_wrapper)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:1366(_fixupParents)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:483(Union)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:150(_path_is_mode_type)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:247(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:569(_check_for_existing_members)\n",
      "        6    0.000    0.000    0.000    0.000 enum.py:579(_get_mixins_)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:137(_type_convert)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:491(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_schema}\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:357(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 typing_extensions.py:169(_should_collect_from_parameters)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:1435(__init__)\n",
      "       13    0.000    0.000    0.000    0.000 sre_parse.py:234(__next)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:482(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:159(_path_isfile)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:173(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1356(_path_importer_cache)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1089(path_stats)\n",
      "      2/1    0.000    0.000    0.000    0.000 typing.py:306(inner)\n",
      "       23    0.000    0.000    0.000    0.000 sre_parse.py:165(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:436(_parse_sub)\n",
      "        3    0.000    0.000    0.000    0.000 JpegImagePlugin.py:182(COM)\n",
      "       60    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
      "        1    0.000    0.000    0.002    0.002 dataloader.py:661(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:303(IFDRational)\n",
      "       37    0.000    0.000    0.000    0.000 _collections_abc.py:409(__subclasshook__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:523(Optional)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:48(_new_module)\n",
      "       24    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
      "        1    0.000    0.000    0.000    0.000 typing_extensions.py:181(_collect_type_vars)\n",
      "        1    0.000    0.000    0.705    0.705 fetch.py:46(fetch)\n",
      "        8    0.000    0.000    0.000    0.000 typing.py:935(_is_dunder)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:74(create_fetcher)\n",
      "       60    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:82(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 abc.py:105(__new__)\n",
      "        5    0.000    0.000    0.000    0.000 hacks.py:26(_check_iterable)\n",
      "      2/1    0.000    0.000    0.000    0.000 typing.py:401(__getitem__)\n",
      "        4    0.000    0.000    0.000    0.000 Image.py:3452(register_extensions)\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:219(_acquireLock)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:267(_remove_dups_flatten)\n",
      "       10    0.000    0.000    0.000    0.000 __init__.py:89(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:62(BmpImageFile)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:986(__and__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:664(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 sre_compile.py:265(_compile_charset)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:225(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:53(PpmImageFile)\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        8    0.000    0.000    0.000    0.000 enum.py:12(_is_descriptor)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:165(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:826(find_spec)\n",
      "        2    0.000    0.000    0.000    0.000 sampler.py:241(__iter__)\n",
      "        7    0.000    0.000    0.000    0.000 Image.py:3418(register_save)\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:1872(AppendingTiffWriter)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:359(__call__)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:622(_code)\n",
      "       13    0.000    0.000    0.000    0.000 typing.py:705(__eq__)\n",
      "       26    0.000    0.000    0.000    0.000 TiffImagePlugin.py:388(_delegate)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:1498(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:497(__call__)\n",
      "       23    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.006    0.006 collate.py:142(<listcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1040(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:960(ImageFileDirectory_v1)\n",
      "        1    0.000    0.000    0.006    0.006 collate.py:204(default_collate)\n",
      "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:360(PngStream)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:1022(<genexpr>)\n",
      "       11    0.000    0.000    0.000    0.000 sre_parse.py:255(get)\n",
      "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:162(ChunkStream)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "       13    0.000    0.000    0.000    0.000 _binary.py:84(i32be)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:98(_get_distributed_settings)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:180(_path_isabs)\n",
      "        9    0.000    0.000    0.000    0.000 enum.py:245(<genexpr>)\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        1    0.000    0.000    0.000    0.000 ImageChops.py:1(<module>)\n",
      "        7    0.000    0.000    0.000    0.000 Image.py:3407(register_mime)\n",
      "       20    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        5    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\n",
      "        1    0.000    0.000    0.002    0.002 dataloader.py:383(_get_iterator)\n",
      "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:254(iTXt)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:1059(TiffImageFile)\n",
      "        9    0.000    0.000    0.000    0.000 sre_parse.py:173(append)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:423(__getattr__)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:683(is_initialized)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:485(_get_literal_prefix)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:412(has_location)\n",
      "       19    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 Image.py:3473(register_decoder)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:515(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:1261(append)\n",
      "        3    0.000    0.000    0.000    0.000 Image.py:3429(register_save_all)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:198(<dictcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 sre_parse.py:112(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:228(_releaseLock)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:714(__hash__)\n",
      "        4    0.000    0.000    0.000    0.000 sre_parse.py:356(_escape)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:746(find_spec)\n",
      "        8    0.000    0.000    0.000    0.000 sre_parse.py:161(__len__)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:723(PngImageFile)\n",
      "        1    0.000    0.000    0.000    0.000 GifImagePlugin.py:63(GifImageFile)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:678(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:947(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 ImageFile.py:85(ImageFile)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:286(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:253(_deduplicate)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:403(WORLD)\n",
      "        1    0.000    0.000    0.000    0.000 GifImagePlugin.py:39(LoadingStrategy)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:516(_get_charset_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 JpegImagePlugin.py:346(JpegImageFile)\n",
      "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:99(Disposal)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:7(is_available)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "       15    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:928(fix_flags)\n",
      "        2    0.000    0.000    0.000    0.000 re.py:249(compile)\n",
      "        4    0.000    0.000    0.000    0.000 sre_compile.py:619(isstring)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.002    0.002 dataloader.py:428(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 fetch.py:8(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 sre_parse.py:287(tell)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1710(getEffectiveLevel)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:447(_simple)\n",
      "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:138(<dictcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:71(_relax_case)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:786(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:193(_checkLevel)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1065(get_filename)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.vars}\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:874(create_module)\n",
      "        1    0.000    0.000    0.000    0.000 ImageFile.py:673(PyDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 sre_parse.py:82(groups)\n",
      "        1    0.000    0.000    0.000    0.000 ImageFile.py:358(Parser)\n",
      "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:120(Blend)\n",
      "        4    0.000    0.000    0.000    0.000 sre_parse.py:250(match)\n",
      "        1    0.000    0.000    0.000    0.000 ImageFile.py:722(PyEncoder)\n",
      "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:680(decorator)\n",
      "        4    0.000    0.000    0.000    0.000 sre_compile.py:477(_get_iscased)\n",
      "        2    0.000    0.000    0.000    0.000 worker.py:89(get_worker_info)\n",
      "        1    0.000    0.000    0.000    0.000 _collections_abc.py:315(__subclasshook__)\n",
      "        1    0.000    0.000    0.000    0.000 ImageFile.py:601(PyCodec)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1307(disable)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:110(num_samples)\n",
      "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:679(_register_writer)\n",
      "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:668(_register_loader)\n",
      "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:149(PpmPlainDecoder)\n",
      "        2    0.000    0.000    0.000    0.000 3599899832.py:21(__len__)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'mro' of 'type' objects}\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:380(__repr__)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'pop' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:276(PngInfo)\n",
      "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(Iterator)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:443(_auto_collation)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:169(__setitem__)\n",
      "        1    0.000    0.000    0.000    0.000 ImageSequence.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:622(_next_index)\n",
      "        1    0.000    0.000    0.000    0.000 ImageFile.py:328(StubImageFile)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:323(default_pg)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:362(DibImageFile)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 ImageFile.py:590(PyCodecState)\n",
      "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:1089(_idat)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:288(BmpRleDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:447(_index_sampler)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:89(annotate)\n",
      "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:1100(_fdat)\n",
      "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:279(PpmDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile.run(\"next(iter(pytorch_dl))\", sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.000    0.000 base_iterator.py:450(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 pytorch.py:203(__next__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile.run(\"next(iter(labelled_loader))\", sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648 ms  47.4 ms per loop (mean  std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5\n",
    "next(iter(pytorch_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.2 ms  1.15 ms per loop (mean  std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5\n",
    "next(iter(labelled_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584686beff524893996f7c96888dc5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(labelled_loader, total=len(pytorch_dl)):\n",
    "    continue\n",
    "\n",
    "labelled_loader.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d391e6ba77664c948919a4ab42a4ada5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(pytorch_dl, total=len(pytorch_dl)):\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - DALI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c560239d004e2da594161d33b5798e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d271693bcbb1464da39b51d532aa8d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-08-14 10:34:59 3585955:3585955 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "[W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "STAGE:2023-08-14 10:34:59 3585955:3585955 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-14 10:34:59 3585955:3585955 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-08-14 10:35:00 3585955:3585955 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-08-14 10:35:00 3585955:3585955 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-14 10:35:00 3585955:3585955 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (gt.argmax(dim=-1)==pred).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/image-dali'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for epoch in tqdm(range(1), leave=True):\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "        \n",
    "        for i, (labelled_data) in enumerate(tqdm(labelled_loader, total=len(pytorch_dl), leave=False)):\n",
    "            # lab, unlab = batch\n",
    "            inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "            inp = inp.to(DEVICE)\n",
    "            y = y.reshape(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inp)\n",
    "\n",
    "            loss = F.cross_entropy(outputs, y)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            prof.step()\n",
    "        \n",
    "        # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "        # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "        labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1de4ace1f5488281b2f8418abf3845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c293d63421847408c1a90901b941c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (ft.argmax(dim=)).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1), leave=True):\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    for i, (labelled_data) in enumerate(tqdm(labelled_loader, total=len(pytorch_dl), leave=False)):\n",
    "        # lab, unlab = batch\n",
    "        inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "        inp = inp.to(DEVICE)\n",
    "        y = y.reshape(-1).to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inp)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, y)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "    # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "    labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Native Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721c19586b8d49fb82991d3592b6d9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237db0d0efa34a94a8a6d5185844ddbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-08-14 10:35:16 3585955:3585955 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-08-14 10:35:19 3585955:3585955 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-14 10:35:19 3585955:3585955 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-08-14 10:35:25 3585955:3585955 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-08-14 10:35:27 3585955:3585955 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-14 10:35:27 3585955:3585955 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': precision_score}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/image-pytorch'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for epoch in tqdm(range(1), leave=True):\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        # epoch_test_loss = 0\n",
    "        \n",
    "        for i, (labelled_data) in enumerate(tqdm(pytorch_dl, total=len(pytorch_dl), leave=False)):\n",
    "            # lab, unlab = batch\n",
    "            # inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "            inp, y = labelled_data\n",
    "            inp = inp.to(DEVICE)\n",
    "            y = y.reshape(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inp)\n",
    "\n",
    "            loss = F.cross_entropy(outputs, y)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            prof.step()\n",
    "        \n",
    "        # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "        # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "        # labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba843f30563c4ba6866f3599802bf337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f287a50372024dac9fdba84a75733aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (ft.argmax(dim=)).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1), leave=True):\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    for i, (labelled_data) in enumerate(tqdm(pytorch_dl, total=len(pytorch_dl), leave=False)):\n",
    "        \n",
    "        inp, y = labelled_data\n",
    "        inp = inp.to(DEVICE)\n",
    "        y = y.reshape(-1).to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inp)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, y)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "    # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "    # labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Pytorch Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316eaa4d9a304641b408125627999dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890b06be585147dd9e6678edd5653567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-08-13 17:42:41 3306472:3306472 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-08-13 17:42:42 3306472:3306472 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-13 17:42:42 3306472:3306472 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-08-13 17:42:42 3306472:3306472 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-08-13 17:42:42 3306472:3306472 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-13 17:42:42 3306472:3306472 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (gt.argmax(dim=-1)==pred).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/dali-expanded'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for epoch in tqdm(range(1), leave=True):\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "        \n",
    "        for i, (labelled_data) in enumerate(tqdm(labelled_loader, total=len(pytorch_dl), leave=False)):\n",
    "            # lab, unlab = batch\n",
    "            inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "            inp = inp.to(DEVICE)\n",
    "            y = y.reshape(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inp)\n",
    "\n",
    "            loss = F.cross_entropy(outputs, y)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            prof.step()\n",
    "        \n",
    "        # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "        # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "        labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls                                                                      Input Shapes  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "autograd::engine::evaluate_function: ConvolutionBack...         0.57%     786.000us        10.53%      14.463ms     241.050us       0.000us         0.00%      28.460ms     474.333us           0 b           0 b      -1.01 Gb      -2.61 Gb            60                                                                                []  \n",
      "                                          ProfilerStep*        39.10%      53.699ms        80.81%     110.985ms      36.995ms       0.000us         0.00%      25.172ms       8.391ms         512 b          20 b           0 b      -3.72 Gb             3                                                                                []  \n",
      "autograd::engine::evaluate_function: CudnnBatchNormB...         0.57%     784.000us         4.12%       5.653ms      94.217us       0.000us         0.00%      12.644ms     210.733us           0 b           0 b      -1.24 Gb      -3.03 Gb            60                                                                                []  \n",
      "void cudnn::ops::nchwToNhwcKernel<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us       9.767ms        11.71%       9.767ms      28.558us           0 b           0 b           0 b           0 b           342                                                                                []  \n",
      "                                   ConvolutionBackward0         0.04%      60.000us         1.43%       1.963ms     163.583us       0.000us         0.00%       8.354ms     696.167us           0 b           0 b     601.69 Mb           0 b            12                                                                [[64, 64, 56, 56]]  \n",
      "                             aten::convolution_backward         0.77%       1.059ms         1.39%       1.903ms     158.583us       8.354ms        10.02%       8.354ms     696.167us           0 b           0 b     601.69 Mb     600.00 Mb            12  [[64, 64, 56, 56], [64, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [],  \n",
      "                                   ConvolutionBackward0         0.07%      93.000us         1.95%       2.680ms     178.667us       0.000us         0.00%       6.258ms     417.200us           0 b           0 b     526.50 Mb           0 b            15                                                               [[64, 128, 28, 28]]  \n",
      "                                   ConvolutionBackward0         0.06%      78.000us         2.58%       3.548ms     236.533us       0.000us         0.00%       5.008ms     333.867us           0 b           0 b     283.64 Mb           0 b            15                                                               [[64, 256, 14, 14]]  \n",
      "                                   ConvolutionBackward0         0.07%      91.000us         3.30%       4.526ms     301.733us       0.000us         0.00%       5.000ms     333.333us           0 b           0 b     224.62 Mb           0 b            15                                                                 [[64, 512, 7, 7]]  \n",
      "                                CudnnBatchNormBackward0         0.05%      63.000us         0.60%     819.000us      68.250us       0.000us         0.00%       4.834ms     402.833us           0 b           0 b     600.01 Mb           0 b            12                                                                [[64, 64, 56, 56]]  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 137.344ms\n",
      "Self CUDA time total: 83.379ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
