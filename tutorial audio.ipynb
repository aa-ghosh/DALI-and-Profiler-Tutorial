{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL FOR DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torchaudio as ta\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, WeightedRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import librosa\n",
    "\n",
    "import cv2\n",
    "import cProfile as profile\n",
    "\n",
    "from nvidia.dali import pipeline_def\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.math as nmath\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator as PyTorchIterator\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator as GenIterator\n",
    "from nvidia.dali.plugin.pytorch import LastBatchPolicy\n",
    "import math\n",
    "\n",
    "DEVICE = 'cuda:1'\n",
    "DEVICE = DEVICE if torch.cuda.is_available() else 'cpu'\n",
    "THREADS = 4\n",
    "LOGSDIR = './runs'\n",
    "DATADIR = Path('./birdclef')\n",
    "TRAIN_DATA = DATADIR/'train_audio'\n",
    "EPOCHS = 1\n",
    "BATCHSIZE = 64\n",
    "# MU = 7\n",
    "TOTAL_ITERS = None\n",
    "NUMWORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import AutoLogger\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['primary_label', 'secondary_labels', 'type', 'latitude', 'longitude',\n",
       "       'scientific_name', 'common_name', 'author', 'license', 'rating', 'time',\n",
       "       'url', 'filename'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled = pd.read_csv(DATADIR/'train_metadata.csv')\n",
    "# labelled = labelled.loc[labelled.duration>=10].reset_index(drop=True)\n",
    "labelled.columns\n",
    "# labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afrsil1/XC125458.ogg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled.filename[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    seed=2022\n",
    "    num_fold = 5\n",
    "    sample_rate= 32_000\n",
    "    n_fft=1024\n",
    "    hop_length=512\n",
    "    n_mels=64\n",
    "    duration=10\n",
    "    num_samples=10*32_000\n",
    "    # num_classes = 152\n",
    "    # train_batch_size = 32\n",
    "    # valid_batch_size = 64\n",
    "    # model_name = 'resnet50'\n",
    "    # # epochs = 2\n",
    "    # # device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 988056]), 32000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 10\n",
    "signal, sr = ta.load(TRAIN_DATA/f\"{labelled.filename[idx]}\")\n",
    "signal.shape, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0518e-05,  0.0000e+00, -3.0518e-05,  ...,  0.0000e+00,\n",
       "          0.0000e+00, -3.0518e-05],\n",
       "        [ 0.0000e+00,  0.0000e+00, -3.0518e-05,  ...,  0.0000e+00,\n",
       "          3.0518e-05,  3.0518e-05]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sr = librosa.load(TRAIN_DATA/f\"{labelled.filename[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    def __init__(self, path, df, transforms, batch_size, sample_rate=32_000,\n",
    "            label_list=None, total_len=0, shuffle=False, duration=10):\n",
    "        self.df = df\n",
    "        # self.labelled = is_labelled\n",
    "        self.total_len = total_len\n",
    "        # self.strong_trans = strong_trans\n",
    "        self.sample_rate = sample_rate\n",
    "        self.trans = transforms\n",
    "        self.path = Path(path)\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.label_list = label_list\n",
    "        self.duration = duration\n",
    "        # if self.labelled:\n",
    "        if not self.label_list:\n",
    "            self.label_list = self.df.primary_label.unique().tolist()\n",
    "            sorted(self.label_list)\n",
    "        class_w = (self.df.shape[0]/self.df.primary_label.value_counts())\n",
    "        # print(class_w)\n",
    "\n",
    "        self.num_samples = self.sample_rate*self.duration\n",
    "        self.weights = self.df.primary_label.apply(lambda x: class_w[x]).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.indices = list(range(len(self)))\n",
    "        if self.shuffle:\n",
    "            shuffle(self.indices)\n",
    "        self.total_batches = 0\n",
    "        self.i = 0\n",
    "        self.n = len(self)\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        batch_2 = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            if (self.i == self.n) and (not self.total_len):\n",
    "                self.__iter__()\n",
    "                raise StopIteration()\n",
    "            \n",
    "            \n",
    "            row = self.df.iloc[self.indices[self.i]]\n",
    "            # image = row.path\n",
    "            \n",
    "            f = open(self.path/f\"{row.filename}\", 'rb')\n",
    "            img = (np.frombuffer(f.read(), dtype=np.uint8))    \n",
    "            batch.append(img)\n",
    "            f.close()\n",
    "\n",
    "            # batch.append(librosa.load(self.path/f\"{row.filename}\", sr=self.sample_rate)[0])\n",
    "\n",
    "            batch_2.append(np.array([self.label_list.index(row.primary_label)]))\n",
    "            self.i = (self.i+1)\n",
    "            self.total_batches += 1\n",
    "            if (self.i == self.n) and (not self.total_len):\n",
    "                self.__iter__()\n",
    "                raise StopIteration()\n",
    "            elif (self.total_len) and (self.total_batches == self.total_len):\n",
    "                self.__iter__()\n",
    "                raise StopIteration()\n",
    "            self.i = self.i%self.n\n",
    "        \n",
    "        return (batch, batch_2)\n",
    "            \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # signal, sr = librosa.load(self.path/f\"{row.ebird_code}/{row.filename}\", sr=self.sample_rate)\n",
    "        signal, sr = ta.load(self.path/f\"{row.filename}\")\n",
    "        # signal = torch.tensor(signal)\n",
    "        if sr != self.sample_rate:\n",
    "            resampler = ta.transforms.Resample(sr, self.sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        \n",
    "        if signal.shape[0]>1:\n",
    "            signal = torch.mean(signal, axis=0, keepdim=True)\n",
    "        \n",
    "        # print(signal.shape)\n",
    "\n",
    "        signal = signal.reshape(1, -1)\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "\n",
    "        if signal.shape[1]<self.num_samples:\n",
    "            num_missing_samples = self.num_samples - signal.shape[1]\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = F.pad(signal, last_dim_padding)\n",
    "        \n",
    "        mel = self.trans(signal)\n",
    "        X = torch.cat([mel, mel, mel])\n",
    "        max_val = torch.abs(X).max()\n",
    "        X = X/max_val\n",
    "        y = self.label_list.index(row.primary_label)\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExternalLabelledSourcePipeline(batch_size, num_threads, device_id, external_data, device):\n",
    "    pipe = Pipeline(batch_size, num_threads, device_id,)\n",
    "    with pipe:\n",
    "        encoded, y = fn.external_source(source=external_data, num_outputs=2, dtype=[types.UINT8, types.INT64])\n",
    "        audio, sr = fn.decoders.audio(encoded, dtype=types.FLOAT, downmix=True, sample_rate=config.sample_rate)\n",
    "        # audio = types.Constant(device=device, value=signal)\n",
    "        # if device=='gpu':\n",
    "        audio = audio.gpu()\n",
    "        audio = fn.pad(audio[:config.num_samples], shape=config.num_samples)\n",
    "        spectrogram = fn.spectrogram(audio, device=device, nfft=config.n_fft,\n",
    "                                window_length=config.n_fft,\n",
    "                                window_step=config.hop_length)\n",
    "        mel_spectrogram = fn.mel_filter_bank(spectrogram, sample_rate=config.sample_rate, nfilter = config.n_mels, \n",
    "                                             freq_high = 8000.0)\n",
    "        mel_spectrogram_dB = fn.to_decibels(mel_spectrogram, multiplier = 10.0, cutoff_db = -80)\n",
    "        stacked = fn.stack(mel_spectrogram_dB, mel_spectrogram_dB, mel_spectrogram_dB, axis=0)\n",
    "        stacked = stacked/fn.reductions.max(nmath.abs(stacked))\n",
    "        pipe.set_outputs(stacked, y)\n",
    "    return pipe\n",
    "\n",
    "\n",
    "mel_spectrogram = ta.transforms.MelSpectrogram(sample_rate=config.sample_rate, \n",
    "                                                      n_fft=config.n_fft, \n",
    "                                                      hop_length=config.hop_length, \n",
    "                                                      n_mels=config.n_mels)\n",
    "\n",
    "labelled_iterator = SupervisedDataset(TRAIN_DATA, df=labelled, \n",
    "                                        transforms=mel_spectrogram, \n",
    "                                        batch_size=BATCHSIZE, total_len=None, shuffle=True)\n",
    "\n",
    "pytorch_dl = DataLoader(labelled_iterator, batch_size=BATCHSIZE, shuffle=True, drop_last=True, num_workers=4)\n",
    "\n",
    "pipe = ExternalLabelledSourcePipeline(batch_size=BATCHSIZE, num_threads=THREADS, device_id = int(DEVICE.split(':')[-1]),\n",
    "                              external_data = labelled_iterator, device='gpu')\n",
    "\n",
    "labelled_loader = GenIterator(pipe, output_map=['x', 'y'], \n",
    "                      last_batch_padded=True, last_batch_policy=LastBatchPolicy.PARTIAL)\n",
    "# pipe.build()\n",
    "# cpu_output = pipe.run()\n",
    "# audio_data = cpu_output[0].at(1)\n",
    "# # sampling_rate = cpu_output[2].at(0)\n",
    "# # print(\"Sampling rate:\", sampling_rate, \"[Hz]\")\n",
    "# print(\"Audio data:\", audio_data.shape)\n",
    "# audio_data = audio_data.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @pipeline_def\n",
    "# def audio_decoder_pipe():\n",
    "#     # encoded, _ = fn.readers.file(file_root=audio_files)\n",
    "#     encoded, y = fn.external_source(source=labelled_iterator, num_outputs=2, dtype=[types.FLOAT, types.INT64])\n",
    "#     # audio, sr = fn.decoders.audio(encoded, dtype=types.FLOAT)\n",
    "#     # print(audio)\n",
    "#     audio = types.Constant(device='gpu', value=audio)\n",
    "#     spectrogram = fn.spectrogram(audio, device='gpu', nfft=config.n_fft, window_length=config.n_fft,\n",
    "#                                  window_step=config.hop_length)\n",
    "#     # mel_spectrogram = fn.mel_filter_bank(spectrogram, sample_rate=config.sample_rate, nfilter = config.n_mels, \n",
    "#     #                                         freq_high = 8000.0)\n",
    "#     # mel_spectrogram_dB = fn.to_decibels(mel_spectrogram, multiplier = 10.0, cutoff_db = -80)\n",
    "#     # images = dali_weak_aug(images)\n",
    "#     return spectrogram, y, sr\n",
    "\n",
    "# pipe = audio_decoder_pipe(batch_size=64, num_threads=1, device_id=0)\n",
    "# pipe.build()\n",
    "# cpu_output = pipe.run()\n",
    "# audio_data = cpu_output[0].as_cpu().at(0)\n",
    "# sampling_rate = cpu_output[2].as_cpu().at(0)\n",
    "# print(\"Sampling rate:\", sampling_rate, \"[Hz]\")\n",
    "# print(\"Audio data:\", audio_data)\n",
    "# audio_data = audio_data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @pipeline_def\n",
    "# def mel_spectrogram_pipe(nfft, window_length, window_step, device='cpu'):\n",
    "#     audio, y = fn.external_source(source=labelled_iterator, num_outputs=2, dtype=[types.FLOAT, types.INT64])\n",
    "#     # encoded, y = fn.readers.file(file_root=str(TRAIN_DATA))\n",
    "#     # audio, sr = fn.decoders.audio(encoded, dtype=types.FLOAT)\n",
    "\n",
    "#     # audio = types.Constant(device=device, value=)\n",
    "#     # print(audio)\n",
    "#     spectrogram = fn.spectrogram(audio, device=device, nfft=nfft,\n",
    "#                                  window_length=window_length,\n",
    "#                                  window_step=window_step)\n",
    "#     mel_spectrogram = fn.mel_filter_bank(spectrogram, sample_rate=config.sample_rate, nfilter = config.n_mels, freq_high = 8000.0)\n",
    "#     mel_spectrogram_dB = fn.to_decibels(mel_spectrogram, multiplier = 10.0, cutoff_db = -80)\n",
    "#     return mel_spectrogram_dB, y\n",
    "\n",
    "\n",
    "# pipe = mel_spectrogram_pipe(device='cpu', batch_size=64, num_threads=1, device_id=1,\n",
    "#                             nfft=config.n_fft, window_length=config.n_fft, window_step=config.hop_length)\n",
    "# pipe.build()\n",
    "# outputs = pipe.run()\n",
    "# mel_spectrogram_dali_db = np.array(outputs[0][0]).shape\n",
    "# # labels = np.array(outputs[1][2])\n",
    "# mel_spectrogram_dali_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7 function calls in 0.001 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    0.001    0.001 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.001    0.001 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.000    0.000 pytorch.py:203(__next__)\n",
      "        1    0.000    0.000    0.000    0.000 base_iterator.py:450(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile.run(\"next(iter(labelled_loader))\", sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         5106 function calls (4512 primitive calls) in 8.536 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        7    8.212    1.173    8.212    1.173 {method 'poll' of 'select.poll' objects}\n",
      "        4    0.241    0.060    0.242    0.060 {built-in method posix.fork}\n",
      "       20    0.034    0.002    0.035    0.002 synchronize.py:50(__init__)\n",
      "       85    0.022    0.000    0.022    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.007    0.007    8.536    8.536 <string>:1(<module>)\n",
      "       16    0.001    0.000    0.001    0.000 socket.py:543(send)\n",
      "        1    0.001    0.001    0.310    0.310 dataloader.py:993(__init__)\n",
      "        4    0.001    0.000    0.243    0.061 popen_fork.py:62(_launch)\n",
      "        5    0.001    0.000    0.001    0.000 synchronize.py:232(__exit__)\n",
      "       42    0.001    0.000    0.001    0.000 {built-in method posix.read}\n",
      "        1    0.001    0.001    0.001    0.001 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
      "       28    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "        4    0.000    0.000    0.249    0.062 process.py:110(start)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.randperm}\n",
      "        5    0.000    0.000    0.036    0.007 queues.py:37(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 util.py:186(__init__)\n",
      "      577    0.000    0.000    0.002    0.000 sampler.py:117(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.037    0.007 context.py:100(Queue)\n",
      "       29    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.003    0.001 {built-in method _pickle.loads}\n",
      "       20    0.000    0.000    0.001    0.000 tempfile.py:153(__next__)\n",
      "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7f106c1e4550}\n",
      "   652/74    0.000    0.000    3.217    0.043 {built-in method builtins.next}\n",
      "       13    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}\n",
      "        8    0.000    0.000    0.004    0.001 iostream.py:471(flush)\n",
      "       20    0.000    0.000    0.000    0.000 random.py:519(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "        4    0.000    0.000    0.249    0.062 context.py:278(_Popen)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:80(__init__)\n",
      "        4    0.000    0.000    0.020    0.005 queues.py:161(_start_thread)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method torch.tensor}\n",
      "       20    0.000    0.000    0.000    0.000 random.py:506(choices)\n",
      "        4    0.000    0.000    0.000    0.000 __init__.py:228(_releaseLock)\n",
      "        5    0.000    0.000    0.000    0.000 connection.py:516(Pipe)\n",
      "        4    0.000    0.000    0.248    0.062 popen_fork.py:15(__init__)\n",
      "       17    0.000    0.000    0.000    0.000 threading.py:236(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 queues.py:71(_reset)\n",
      "       25    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
      "       11    0.000    0.000    0.035    0.003 context.py:65(Lock)\n",
      "        9    0.000    0.000    0.002    0.000 sampler.py:247(<listcomp>)\n",
      "       16    0.000    0.000    0.000    0.000 connection.py:117(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 socket.py:220(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.empty}\n",
      "  195/189    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       42    0.000    0.000    0.001    0.000 connection.py:374(_recv)\n",
      "       16    0.000    0.000    0.001    0.000 iostream.py:202(schedule)\n",
      "       20    0.000    0.000    0.000    0.000 tempfile.py:142(rng)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        1    0.000    0.000    0.001    0.001 profiler.py:482(__init__)\n",
      "        1    0.000    0.000    3.215    3.215 dataloader.py:628(__next__)\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:623(SocketClient)\n",
      "       25    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)\n",
      "        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)\n",
      "        4    0.000    0.000    0.249    0.062 context.py:222(_Popen)\n",
      "        6    0.000    0.000    0.002    0.000 resource_sharer.py:81(get_connection)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:146(_type_check)\n",
      "       11    0.000    0.000    0.022    0.002 threading.py:288(wait)\n",
      "       44    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:404(parent)\n",
      "        7    0.000    0.000    8.212    1.173 connection.py:917(wait)\n",
      "        7    0.000    0.000    8.212    1.173 selectors.py:403(select)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _new_shared_fd_cpu}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}\n",
      "      2/1    0.000    0.000    0.001    0.001 typing.py:306(inner)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _hashlib.hmac_new}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'recvmsg' of '_socket.socket' objects}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:827(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_operation_overload}\n",
      "  116/112    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        6    0.000    0.000    0.001    0.000 connection.py:747(answer_challenge)\n",
      "        6    0.000    0.000    0.003    0.000 reductions.py:306(rebuild_storage_fd)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:491(__enter__)\n",
      "        6    0.000    0.000    0.000    0.000 reduction.py:153(recvfds)\n",
      "       13    0.000    0.000    0.020    0.002 queues.py:86(put)\n",
      "        3    0.000    0.000    3.213    1.071 queues.py:98(get)\n",
      "        1    0.000    0.000    0.022    0.022 dataloader.py:1086(_reset)\n",
      "       20    0.000    0.000    0.001    0.000 __init__.py:7(_make_name)\n",
      "       21    0.000    0.000    0.001    0.000 connection.py:413(_recv_bytes)\n",
      "        4    0.000    0.000    0.005    0.001 util.py:433(_flush_std_streams)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1016(__init__)\n",
      "        9    0.000    0.000    0.022    0.002 dataloader.py:1347(_try_put_index)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:495(__exit__)\n",
      "       24    0.000    0.000    0.000    0.000 threading.py:1169(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:239(__init__)\n",
      "       12    0.000    0.000    0.022    0.002 threading.py:589(wait)\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method posix.write}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:567(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:447(__getattr__)\n",
      "       18    0.000    0.000    0.000    0.000 connection.py:181(send_bytes)\n",
      "       21    0.000    0.000    0.001    0.000 connection.py:208(recv_bytes)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:545(__init__)\n",
      "        1    0.000    0.000    5.004    5.004 dataloader.py:1400(_shutdown_workers)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:1498(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method marshal.loads}\n",
      "        8    0.000    0.000    0.000    0.000 _weakrefset.py:86(add)\n",
      "       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler.}\n",
      "       11    0.000    0.000    0.035    0.003 synchronize.py:161(__init__)\n",
      "      2/1    0.000    0.000    8.536    8.536 {built-in method builtins.exec}\n",
      "       25    0.000    0.000    0.000    0.000 weakref.py:353(__init__)\n",
      "       24    0.000    0.000    0.000    0.000 connection.py:390(_send_bytes)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch._C._error_if_any_worker_fails}\n",
      "        6    0.000    0.000    0.000    0.000 reduction.py:38(__init__)\n",
      "       17    0.000    0.000    0.000    0.000 threading.py:359(notify)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}\n",
      "        4    0.000    0.000    0.019    0.005 threading.py:916(start)\n",
      "       22    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        6    0.000    0.000    0.000    0.000 reductions.py:98(rebuild_tensor)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:483(Union)\n",
      "        3    0.000    0.000    0.000    0.000 signal_handling.py:63(handler)\n",
      "       11    0.000    0.000    0.002    0.000 sampler.py:241(__iter__)\n",
      "       38    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x743500}\n",
      "       25    0.000    0.000    0.000    0.000 weakref.py:348(__new__)\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:732(deliver_challenge)\n",
      "       24    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:921(_find_spec)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    3.213    3.213 dataloader.py:1298(_next_data)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "      4/1    0.000    0.000    0.310    0.310 {built-in method builtins.iter}\n",
      "       12    0.000    0.000    0.000    0.000 hmac.py:38(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 signal.py:34(_enum_to_int)\n",
      "        1    0.000    0.000    0.001    0.001 typing.py:523(Optional)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:664(__init__)\n",
      "        6    0.000    0.000    0.002    0.000 resource_sharer.py:55(detach)\n",
      "        8    0.000    0.000    0.000    0.000 typing.py:986(__setattr__)\n",
      "       12    0.000    0.000    0.000    0.000 hmac.py:66(_init_hmac)\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:235(register)\n",
      "        6    0.000    0.000    0.002    0.000 connection.py:493(Client)\n",
      "       82    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 signal.py:60(getsignal)\n",
      "        6    0.000    0.000    0.000    0.000 reduction.py:186(recv_handle)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}\n",
      "        4    0.000    0.000    5.003    1.251 popen_fork.py:36(wait)\n",
      "        4    0.000    0.000    0.000    0.000 hacks.py:26(_check_iterable)\n",
      "       49    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        6    0.000    0.000    0.000    0.000 reductions.py:28(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 reduction.py:48(dumps)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1536(find_spec)\n",
      "        2    0.000    0.000    0.000    0.000 typing_extensions.py:169(_should_collect_from_parameters)\n",
      "       13    0.000    0.000    0.000    0.000 threading.py:1430(current_thread)\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:352(register)\n",
      "        6    0.000    0.000    0.000    0.000 reductions.py:339(rebuild_typed_storage)\n",
      "        4    0.000    0.000    5.003    1.251 process.py:142(join)\n",
      "       12    0.000    0.000    0.000    0.000 connection.py:95(address_type)\n",
      "        7    0.000    0.000    0.000    0.000 util.py:205(__call__)\n",
      "       13    0.000    0.000    0.000    0.000 popen_fork.py:24(poll)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "       44    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        5    0.000    0.000    0.000    0.000 context.py:85(BoundedSemaphore)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_schema}\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:497(__call__)\n",
      "       29    0.000    0.000    0.000    0.000 threading.py:264(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:267(_remove_dups_flatten)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open_code}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:61(_cleanup)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 queues.py:153(cancel_join_thread)\n",
      "        1    0.000    0.000    0.310    0.310 dataloader.py:383(_get_iterator)\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:269(close)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HMAC' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:950(get_code)\n",
      "        6    0.000    0.000    0.000    0.000 _utils.py:145(_rebuild_tensor)\n",
      "       24    0.000    0.000    0.000    0.000 connection.py:365(_send)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method posix.fstat}\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:348(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 range.py:946(__len__)\n",
      "       16    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:612(_reset)\n",
      "        1    0.000    0.000    0.000    0.000 random.py:128(seed)\n",
      "        6    0.000    0.000    0.000    0.000 reductions.py:65(get)\n",
      "      160    0.000    0.000    0.000    0.000 {built-in method math.floor}\n",
      "        6    0.000    0.000    0.000    0.000 socket.py:504(detach)\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1301(_make_invoke_excepthook)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:137(_type_convert)\n",
      "       12    0.000    0.000    0.000    0.000 hmac.py:167(new)\n",
      "       24    0.000    0.000    0.000    0.000 threading.py:1102(_wait_for_tstate_lock)\n",
      "       32    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 dataloader.py:1081(<genexpr>)\n",
      "      160    0.000    0.000    0.000    0.000 {method 'random' of '_random.Random' objects}\n",
      "       12    0.000    0.000    0.000    0.000 hmac.py:151(digest)\n",
      "      2/1    0.000    0.000    0.001    0.001 typing.py:401(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:380(cache_from_source)\n",
      "       29    0.000    0.000    0.000    0.000 threading.py:267(__exit__)\n",
      "       43    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:179(_get_module_lock)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:359(__call__)\n",
      "       21    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:202(send)\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:210(__init__)\n",
      "       57    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)\n",
      "        2    0.000    0.000    0.000    0.000 signal.py:24(_int_to_enum)\n",
      "        6    0.000    0.000    0.000    0.000 reductions.py:69(__setitem__)\n",
      "        6    0.000    0.000    0.000    0.000 storage.py:427(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 socket.py:239(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 context.py:80(Semaphore)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap>:1022(_find_and_load)\n",
      "       28    0.000    0.000    0.000    0.000 threading.py:279(_is_owned)\n",
      "        3    0.000    0.000    3.209    1.070 connection.py:423(_poll)\n",
      "       17    0.000    0.000    0.000    0.000 weakref.py:106(remove)\n",
      "       10    0.000    0.000    0.000    0.000 context.py:237(get_context)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 typing_extensions.py:181(_collect_type_vars)\n",
      "       42    0.000    0.000    0.000    0.000 {method 'write' of '_io.BytesIO' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'dump' of '_pickle.Pickler' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap>:987(_find_and_load_unlocked)\n",
      "        4    0.000    0.000    0.000    0.000 queues.py:204(_finalize_close)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:664(_load_unlocked)\n",
      "       12    0.000    0.000    0.000    0.000 reductions.py:291(fd_id)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:488(check_worker_number_rationality)\n",
      "        1    0.000    0.000    0.001    0.001 synchronize.py:334(set)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:100(acquire)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:234(ident)\n",
      "       44    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:1145(ident)\n",
      "        3    0.000    0.000    3.213    1.071 dataloader.py:1265(_get_data)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:678(__new__)\n",
      "       13    0.000    0.000    0.000    0.000 typing.py:705(__eq__)\n",
      "        1    0.000    0.000    0.000    0.000 popen_fork.py:1(<module>)\n",
      "        1    0.000    0.000    0.310    0.310 dataloader.py:428(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1070(get_data)\n",
      "       32    0.000    0.000    0.000    0.000 threading.py:553(is_set)\n",
      "        6    0.000    0.000    0.000    0.000 storage.py:355(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1531(_get_spec)\n",
      "        6    0.000    0.000    0.000    0.000 socket.py:539(fromfd)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:126(_path_join)\n",
      "       23    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:492(_init_module_attrs)\n",
      "        6    0.000    0.000    0.000    0.000 socket.py:494(_real_close)\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:173(close)\n",
      "       17    0.000    0.000    0.000    0.000 process.py:99(_check_closed)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1399(_get_spec)\n",
      "        6    0.000    0.000    0.000    0.000 socket.py:498(close)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.sched_getaffinity}\n",
      "        2    0.000    0.000    0.000    0.000 1985698509.py:25(__len__)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:128(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:380(__repr__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:721(spec_from_file_location)\n",
      "        4    0.000    0.000    0.000    0.000 __init__.py:219(_acquireLock)\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:216(_fileobj_lookup)\n",
      "        4    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 signal.py:54(signal)\n",
      "        3    0.000    0.000    3.209    1.070 connection.py:253(poll)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:947(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:21(_fileobj_to_fd)\n",
      "       17    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:71(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 threading.py:276(_acquire_restore)\n",
      "        6    0.000    0.000    0.000    0.000 reductions.py:299(storage_from_cache)\n",
      "        3    0.000    0.000    3.213    1.071 dataloader.py:1119(_try_get_data)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:98(_get_distributed_settings)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method posix.urandom}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:203(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:670(_compile_bytecode)\n",
      "       24    0.000    0.000    0.000    0.000 connection.py:138(_check_readable)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:1367(_process_data)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:84(_unpack_uint32)\n",
      "       27    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        6    0.000    0.000    0.000    0.000 selectors.py:276(_key_from_fd)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:1022(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 process.py:94(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:253(_deduplicate)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:132(_path_split)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:140(_path_stat)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:877(exec_module)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:83(_validate_family)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1198(daemon)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 dataloader.py:1374(_mark_worker_as_unavailable)\n",
      "        7    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:244(_verbose_message)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}\n",
      "        1    0.000    0.000    0.000    0.000 popen_fork.py:56(terminate)\n",
      "        1    0.000    0.000    0.000    0.000 context.py:90(Event)\n",
      "        8    0.000    0.000    0.000    0.000 typing.py:935(_is_dunder)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "        1    0.000    0.000    0.000    0.000 popen_fork.py:12(Popen)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:564(module_from_spec)\n",
      "       42    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "        6    0.000    0.000    0.000    0.000 process.py:213(authkey)\n",
      "        7    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 random.py:119(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _socket.dup}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.kill}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        9    0.000    0.000    0.002    0.000 dataloader.py:622(_next_index)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:125(release)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:189(name)\n",
      "        4    0.000    0.000    0.000    0.000 synchronize.py:327(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:169(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1356(_path_importer_cache)\n",
      "       11    0.000    0.000    0.000    0.000 threading.py:273(_release_save)\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:933(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:391(cached)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _signal.signal}\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
      "       21    0.000    0.000    0.000    0.000 context.py:187(get_context)\n",
      "        4    0.000    0.000    0.000    0.000 queues.py:140(close)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1183(daemon)\n",
      "       20    0.000    0.000    0.000    0.000 context.py:197(get_start_method)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:110(num_samples)\n",
      "       24    0.000    0.000    0.000    0.000 connection.py:142(_check_writable)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1431(find_spec)\n",
      "       12    0.000    0.000    0.000    0.000 hmac.py:139(_current)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'setblocking' of '_socket.socket' objects}\n",
      "        1    0.000    0.000    0.000    0.000 popen_fork.py:46(_send_signal)\n",
      "        9    0.000    0.000    0.000    0.000 connection.py:168(fileno)\n",
      "        1    0.000    0.000    0.000    0.000 context.py:75(Condition)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:893(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:296(notify_all)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:153(is_alive)\n",
      "        5    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:683(is_initialized)\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:262(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 {function socket.close at 0x7f106c9ecdc0}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:585(_classify_pyc)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method select.poll}\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:403(WORLD)\n",
      "        8    0.000    0.000    0.000    0.000 connection.py:360(_close)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:270(notify)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:159(_path_isfile)\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:39(_remove)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:144(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:714(__hash__)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:515(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:510(_get_cached)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:89(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "       12    0.000    0.000    0.000    0.000 socket.py:236(__enter__)\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:64(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)\n",
      "        1    0.000    0.000    5.004    5.004 dataloader.py:1477(__del__)\n",
      "        7    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:134(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 synchronize.py:125(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:323(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:618(_validate_timestamp_pyc)\n",
      "        8    0.000    0.000    0.000    0.000 connection.py:130(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:198(cb)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _socket.CMSG_SPACE}\n",
      "        3    0.000    0.000    0.000    0.000 util.py:461(close_fds)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:150(_path_is_mode_type)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:542(_check_name_wrapper)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:205(daemon)\n",
      "       14    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:7(is_available)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:897(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'frombytes' of 'array.array' objects}\n",
      "        6    0.000    0.000    0.000    0.000 process.py:37(current_process)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:826(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:286(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1089(path_stats)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:165(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:48(_new_module)\n",
      "        9    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:357(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {function socket.detach at 0x7f106c9ece50}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method '_weak_ref' of 'torch._C.StorageBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 process.py:128(terminate)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:443(_auto_collation)\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:259(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:173(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:233(_call_with_frames_removed)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        7    0.000    0.000    0.000    0.000 selectors.py:200(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:447(_index_sampler)\n",
      "        5    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
      "        7    0.000    0.000    0.000    0.000 util.py:44(sub_debug)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:180(_path_isabs)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _signal.getsignal}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1040(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:1102(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:323(default_pg)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:746(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:874(create_module)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:390(multiprocessing_context)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:71(_relax_case)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method posix.waitstatus_to_exitcode}\n",
      "        1    0.000    0.000    0.000    0.000 _jit_internal.py:1102(is_scripting)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:412(has_location)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1065(get_filename)\n",
      "        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:89(annotate)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile.run(\"next(iter(pytorch_dl))\", sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 ms ± 91.5 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5\n",
    "next(iter(labelled_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.68 s ± 444 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5\n",
    "next(iter(pytorch_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b8b62391de417692e3636d1ac217f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(labelled_loader, total=len(pytorch_dl)):\n",
    "    continue\n",
    "\n",
    "labelled_loader.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41359c69be8845c3988008fe339bcb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(pytorch_dl, total=len(pytorch_dl)):\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - DALI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6277600b02a4a8bb3727ec3f54d4741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2541c446fb4c88beaefbcea62e9d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-08-14 10:42:44 3585936:3585936 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "[W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "STAGE:2023-08-14 10:42:45 3585936:3585936 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-14 10:42:45 3585936:3585936 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-08-14 10:43:06 3585936:3585936 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-08-14 10:43:08 3585936:3585936 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-14 10:43:08 3585936:3585936 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (gt.argmax(dim=-1)==pred).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/audio-dali'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for epoch in tqdm(range(1), leave=True):\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "        \n",
    "        for i, (labelled_data) in enumerate(tqdm(labelled_loader, total=len(pytorch_dl), leave=False)):\n",
    "            # lab, unlab = batch\n",
    "            inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "            inp = inp.to(DEVICE)\n",
    "            y = y.reshape(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inp)\n",
    "\n",
    "            loss = F.cross_entropy(outputs, y)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            prof.step()\n",
    "        \n",
    "        # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "        # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "        labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bcc1847e58449a896343c517c6fde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6551fb31906549b9a1146a817d644804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (ft.argmax(dim=)).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1), leave=True):\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    for i, (labelled_data) in enumerate(tqdm(labelled_loader, total=len(pytorch_dl), leave=False)):\n",
    "        # lab, unlab = batch\n",
    "        inp, y = labelled_data[0]['x'], labelled_data[0]['y']\n",
    "        inp = inp.to(DEVICE)\n",
    "        y = y.reshape(-1).to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inp)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, y)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "    # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "    labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Native Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89995df1a2db47e49a78d4b938c98a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41de4c4df10410f9a594fda3aa581a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-08-14 10:59:39 3585936:3585936 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-08-14 10:59:42 3585936:3585936 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-14 10:59:42 3585936:3585936 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-08-14 11:00:03 3585936:3585936 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-08-14 11:00:03 3585936:3585936 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-08-14 11:00:03 3585936:3585936 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/audio-pytorch'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=False,\n",
    ") as prof:\n",
    "    for epoch in tqdm(range(1), leave=True):\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "        \n",
    "        for i, (labelled_data) in enumerate(tqdm(pytorch_dl, total=len(pytorch_dl), leave=False)):\n",
    "            # lab, unlab = batch\n",
    "            inp, y = labelled_data\n",
    "            inp = inp.to(DEVICE)\n",
    "            y = y.reshape(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inp)\n",
    "\n",
    "            loss = F.cross_entropy(outputs, y)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            prof.step()\n",
    "        \n",
    "        # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "        # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "        # labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c731d43c1145709ba58165f3b2b777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39484423cd9a4f699c6dfd9a51f3008f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labelled_iterator.label_list), True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "logger = AutoLogger({'precision': lambda gt, pred: (ft.argmax(dim=)).mean()}, tensorboard=True)\n",
    "for epoch in range(2):\n",
    "    logger.epoch_start()\n",
    "    # train_part\n",
    "    for i in range(2):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(0, 'train')\n",
    "        logger.log_metrics(y_true, y_pred, 'train')\n",
    "\n",
    "    # test part\n",
    "    for i in range(1):\n",
    "        y_true = np.random.randint(0,2, size=(5,))\n",
    "        y_pred = np.random.randint(0,2, size=(5,))\n",
    "        logger.log_loss(1, 'test')\n",
    "        logger.log_metrics(y_true, y_pred, 'test')\n",
    "\n",
    "    logger.epoch_end()\n",
    "\"\"\"\n",
    "# model = torch.nn.DataParallel(ImModel(models.resnet18, 1000, None), device_ids=[0,1,2,3]).cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3, \n",
    "                                          epochs=EPOCHS, \n",
    "                                          steps_per_epoch=len(pytorch_dl))\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1), leave=True):\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    epoch_test_loss = 0\n",
    "    \n",
    "    for i, (labelled_data) in enumerate(tqdm(pytorch_dl, total=len(pytorch_dl), leave=False)):\n",
    "        \n",
    "        inp, y = labelled_data\n",
    "        inp = inp.to(DEVICE)\n",
    "        y = y.reshape(-1).to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inp)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, y)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        epoch_train_loss += loss.detach().cpu()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # epoch_train_loss = epoch_train_loss/len(unlabelled_dl)\n",
    "    # writer.add_scalar('Loss_Epoch', epoch_train_loss, epoch)\n",
    "    # labelled_loader.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
